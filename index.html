<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favico.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16X16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-mac-osx.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.7.0',
    exturl: true,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="Java, Architect">
<meta property="og:type" content="website">
<meta property="og:title" content="Architect">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Architect">
<meta property="og:description" content="Java, Architect">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Chris Shang">
<meta property="article:tag" content="Java">
<meta property="article:tag" content=" Architecher">
<meta property="article:tag" content=" Distribute">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Architect - The steps you take don't need to be big. They just need to take you in the right direction.</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Architect" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Architect</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">The steps you take don't need to be big. They just need to take you in the right direction.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/09/ElasticSearch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/09/ElasticSearch/" class="post-title-link" itemprop="url">ElasticSearch</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-03-09 15:47:53 / Modified: 16:24:21" itemprop="dateCreated datePublished" datetime="2020-03-09T15:47:53+08:00">2020-03-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ES-vs-Solr"><a href="#ES-vs-Solr" class="headerlink" title="ES vs Solr"></a>ES vs Solr</h2><ul>
<li><p>对已有数据进行搜索,Solr更快</p>
</li>
<li><p>实时建立索引时,solr会发生阻塞,ES具有明显的优势</p>
</li>
<li><p>随着数据量的增加,Solr的效率会变低,而ES没有明显的变化</p>
</li>
<li><p>Solr利用ZK进行分布式管理,而ES自身带有分布式协调管理功能</p>
</li>
<li><p>Solr支持的数据格式更多,ES只支持JSON</p>
</li>
<li><p>ES是对Lucene进行封装, 用restful的形式去调用, 同时还考虑了海量数据, 实现了分布式, 是一个可以存储海量数据的分布式搜索引擎;</p>
</li>
</ul>
<h2 id="分析文档"><a href="#分析文档" class="headerlink" title="分析文档"></a><strong>分析文档</strong></h2><ol>
<li><p>分析文档主要是对Field域进行分析,分析文档的目的是为了索引</p>
</li>
<li><p>分析文档主要通过分词组件(Tokenizer)和语言处理组件(Linguistic Processor)完成</p>
<p><strong>分词组件</strong></p>
<ul>
<li><p>将Field域中的内容进行分词(不同语言有不同的分词规则)</p>
</li>
<li><p>去除标点符号</p>
</li>
<li><p>去除停用词(stop word)</p>
</li>
<li><p><strong>分词(Tokenize)</strong>之后得到的结果成为词元(<strong>Token</strong>), 对于每一种语言的分词组件(<strong>Tokenizer</strong>)都有一个停词(stop word)集合, the, a, this等</p>
</li>
</ul>
<p><strong>将得到的词元传递给语言处理组件(Linguistic Processor),语言处理组件一般做以下几点:</strong></p>
<ul>
<li><p>变为小写(lowercase)</p>
</li>
<li><p>将单词缩减为词根形式, 如cars到car, 这种操作称为stemming</p>
</li>
<li><p>将单词转变为词根形式, 如drove到drive等, 这种操作称为lemmatization </p>
</li>
</ul>
<p><strong>语言处理组件得到的结果称为term</strong></p>
</li>
</ol>
<h2 id="索引文档"><a href="#索引文档" class="headerlink" title="索引文档"></a><strong>索引文档</strong></h2><ol>
<li><p>索引的目的是为了搜索</p>
</li>
<li><p>将得到的term传给<strong>索引(Indexer)组件</strong>, 索引组件主要做以下几件事情:</p>
<ul>
<li><p>创建term字典</p>
</li>
<li><p>排序term字典</p>
</li>
<li><p>合并term字典(合并相同的词成为文档倒排链表)</p>
</li>
<li><p>最终的索引结构是一种<strong>倒排索引结构</strong>也叫<strong>反向索引结构</strong>, 包括索引和文档两部分, 索引即词汇表,它的规模较小, 而文档集合较大</p>
</li>
</ul>
</li>
</ol>
<h2 id="ES的高可用"><a href="#ES的高可用" class="headerlink" title="ES的高可用"></a><strong>ES的高可用</strong></h2><ul>
<li><p>Master-slave架构, master负责集群状态信息的改变, 并同步给其他slave节点, ES会对数据进行拆分, 每一个分片(shards)会保存多个副本;</p>
</li>
<li><p>只有建立索引和类型(表)会通过master, 数据的写入有个routing规则, 可以route集群, 所以数据写入的压力是分散在整个集群的;</p>
</li>
<li><p>实际应用如(ELK), elasticsearch + logstash(日志收集系统) + kibana(数据可视化平台), 当集群中节点有上百个结点时, 排查日志肯定不能一个一个登录去看, 这时候logstash就起作用了. 还能对错误进行实时报警;</p>
</li>
</ul>
<h2 id="ES倒排索引"><a href="#ES倒排索引" class="headerlink" title="ES倒排索引"></a><strong>ES倒排索引</strong></h2><p>最直白的理解, 就是我们之前背诵诗是背诵题目, 然后是诗的内容. 但是如诗词大会飞花令直接背诵包含某个字如”雪”, “风”的诗却很难想起来. 倒排索引就是以诗中的每个字,作为索引. poem{name: <strong>keyword</strong>, author: <strong>keyword</strong>, dynasty: <strong>keyword</strong>, content: <strong>text</strong>}</p>
<p><img src="/2020/03/09/ElasticSearch/ES%E7%BB%93%E6%9E%84.png" alt="ES倒排索引"></p>
<h2 id="ES的Analyzer"><a href="#ES的Analyzer" class="headerlink" title="ES的Analyzer"></a><strong>ES的Analyzer</strong></h2><p>shopstyle主要是对fts的搜索, index时把productName, retailerName, category tag, brand name, material, color, description等信息copy到fts_text字段中; 然后通过自定义的<strong>analyzer(索引时应用的分析器)</strong> 和<strong>search_analyzer(搜索时用的分析器)</strong>进行索引和查询.</p>
<p>自定义<strong>analyzer</strong>分三个功能:</p>
<ul>
<li><p><strong>char_filter(0个或多个)</strong>: 分词前对对字符串进行按字符进行过滤; char_filter 也可以自定义, 共有三种类型自定义的char_filter, “char_filter”:{“<strong>my_char_filter</strong>”{“type”: “<strong>mapping</strong>”, “<strong>mappings</strong>”:[“curry =&gt; 库里”]}}, 除此之外还有<strong>pattern</strong>(正则)过滤, 和<strong>html strip filter</strong></p>
</li>
<li><p><strong>tokenizer</strong>(分词器, 有且只有一个): 接收字符流, 输出token流. 有十几种. shopstyle使用了<strong>classic</strong>, <strong>a.</strong> 分割”符号+空格” <strong>b.</strong> 拆分连字符, 除token中有一个数字, 这种情况下, token被翻译为产品编号. <strong>c.</strong>把email和 hostname当做一个token; 还使用了<strong>keyword</strong>的tokenizer, 不会被拆分;</p>
</li>
<li><p><strong>token filter(0个或多个)</strong>: token过滤器, 有 lowercase token filter(转小写), stop token filter(删除停用词), 自定义 filter, 继承TokenFilter类,  </p>
</li>
</ul>
<h2 id="ES优化"><a href="#ES优化" class="headerlink" title="ES优化"></a><strong>ES优化</strong></h2><ul>
<li><p>ssd硬盘</p>
</li>
<li><p>routing</p>
</li>
<li><p>分别查询和合并查询</p>
</li>
<li><p>避免使用range查询</p>
</li>
<li><p>JVM GC的选择</p>
</li>
</ul>
<p><strong>ES优化问题:</strong></p>
<ul>
<li><p>第一次搜索的时候，是5~10s，后面反而就快了，可能就几百毫秒?</p>
<p>往ES里index的数据, 实际上都是写到磁盘文件中去了, 查询的时候操作系统会将磁盘文件里的数据自动缓存到FileSystem Cache里面去.ES严重依赖这个cache, 所以FileSystemCache分配的内存要占到机器内存的一半.</p>
</li>
<li><p>只有需要搜索的字段再index到ES中(当然必须包括id), 查出来id之后再去其他数据库中查完整的数据.</p>
</li>
<li><p>如果数据量实在太大, FileSystem Cache无论如何也容纳不了一半的数据, 那么就需要<strong>数据预热</strong>, 对热门搜索要定时刷到cache中.</p>
</li>
<li><p><strong>冷热分离</strong>. 热门搜索数据要放到不同的机器上.</p>
</li>
<li><p><strong>避免</strong>join/nested/parent-child搜索, 能在代码中完成尽量在代码中完成</p>
</li>
<li><p><strong>减少分页</strong>, 使用<strong>Scroll API</strong>代替(正常ES会维护之前翻页的上下文信息, 但是不能维护时间太长,浪费资源, 该api会设定一个存储的时间), 或者<strong>search_after</strong>来代替.shopstyle是将scroll调用的api和search的api进行分离. search_after与scroll api很相似, 但是search_after是无状态的. search_after举例:</p>
<p>首先要理解 search_after 这个功能；<br>例如你现在需要安装id 和 time 进行排序；<br>你获取了第一页的结果后，现在需要获取第二页内容<br>你需要使用第一页最后一条的id 和 time，作为 search_after 的参数chuan传递到查询请求中。<br>下面是样例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SearchAfterBuilder searchAfterBuilder = <span class="keyword">new</span> SearchAfterBuilder(); </span><br><span class="line">searchAfterBuilder.setSortValues(<span class="keyword">new</span> Object[]&#123;<span class="string">"上一页的ID"</span>, <span class="string">"上一页的时间"</span>&#125;);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="ES索引与搜索"><a href="#ES索引与搜索" class="headerlink" title="ES索引与搜索"></a>ES索引与搜索</h2><h3 id="索引时analyzer顺序"><a href="#索引时analyzer顺序" class="headerlink" title="索引时analyzer顺序"></a>索引时analyzer顺序</h3><ol>
<li><p>mapping字段中定义的分词器</p>
</li>
<li><p>索引设置中命名为”default”的分词器</p>
</li>
<li><p>Standard analyzer</p>
</li>
</ol>
<h3 id="查询时analyzer顺序"><a href="#查询时analyzer顺序" class="headerlink" title="查询时analyzer顺序"></a>查询时analyzer顺序</h3><ol>
<li><p>Full-text query中的分词器</p>
</li>
<li><p>定义在mapping字段中的search_analyzer</p>
</li>
<li><p>定义在mapping字段中的analyzer</p>
</li>
<li><p>索引设置中命名为”default_search”的分词器</p>
</li>
<li><p>索引设置中命名为”default”的分词器</p>
</li>
<li><p>Standard analyzer</p>
</li>
</ol>
<h2 id="mapping文件中一些参数的设置需要注意的点"><a href="#mapping文件中一些参数的设置需要注意的点" class="headerlink" title="mapping文件中一些参数的设置需要注意的点"></a>mapping文件中一些参数的设置需要注意的点</h2><ul>
<li><p><strong>copy_to</strong>, 不能通过中间值来复制, 如不能把field1 copy 给field2, 然后再通过field copy给field3. 但是可以同时将field1 copy给field3</p>
</li>
<li><p><strong>doc_values</strong>: 如果确定不需要通过该字段进行排序或聚合, 就将该值设置为false. 能节省磁盘空间. text 类型的字段不支持该值(所以如果想让该字段支持排序或聚合, 就应该设置一个innerfield,类型为keyword)</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;mappings&quot;: &#123;</span><br><span class="line">  	&quot;properties&quot;: &#123;</span><br><span class="line">  	&quot;my_field&quot;: &#123; </span><br><span class="line">			&quot;type&quot;: &quot;text&quot;,</span><br><span class="line">			&quot;fields**&quot;: &#123;</span><br><span class="line">				&quot;keyword&quot;: &#123; </span><br><span class="line">				&quot;type&quot;: &quot;**keyword**&quot; &#125;&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li><p><strong>dynamic</strong>: 是否允许动态添加新字段(不在mapping文件中的字段), false(不允许), true(允许), strict(报错)</p>
</li>
<li><p><strong>fields</strong>:(multi-field) a string field could be mapped as a <strong>text</strong> field for <strong>full-text search</strong>, and as a <strong>keyword</strong> field for <strong>sorting or aggregations,</strong> 另外一种用途是可以将该字段以两种不同的分词器进行索引</p>
</li>
<li><p><strong>normalizer</strong>: 在index和搜索的时候对keyword类型的数据进行normalize处理.</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">"analysis": &#123;</span><br><span class="line">"normalizer": &#123;</span><br><span class="line">"my_normalizer": &#123;</span><br><span class="line">"type": "custom",</span><br><span class="line">  "filter": ["lowercase", "asciifolding"]&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Asciifolding</strong>: 作用是去掉变音符号(如法语)并且能把Unicode字符转化为ASCII来表示.</p>
</li>
<li><p>store: 是否存储该字段的原始值.在某些情况下是有用的, 如果你有一个带有标题、日期和一个非常大的内容字段的文档，你可能希望只检索标题和日期，而不必从一个大的源字段中提取这些字段, 如把title和date设置为:store: true.搜索的时候只检索title和date</p>
<p>GET my_index/_search{</p>
<p>  “<strong>stored_fields</strong>“: [ “title”, “date” ] }</p>
</li>
<li><p><strong>similarity</strong>: 相似度算法, 共有三个值, BM25, classic(tf/idf算法), boolean:当full-text ranking不需要的时候, 并且分数只和是否匹配相关. boolean的similarity会给term一个和query的boost相等的分数.</p>
</li>
</ul>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/20/spring-cloud/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/20/spring-cloud/" class="post-title-link" itemprop="url">spring cloud</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-20 16:36:10" itemprop="dateCreated datePublished" datetime="2020-01-20T16:36:10+08:00">2020-01-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/20/redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/20/redis/" class="post-title-link" itemprop="url">redis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-20 15:04:45" itemprop="dateCreated datePublished" datetime="2020-01-20T15:04:45+08:00">2020-01-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-09 15:45:57" itemprop="dateModified" datetime="2020-03-09T15:45:57+08:00">2020-03-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>高并发下查询一个值，缓存中没有，数据库中也没有，布隆过滤器</p>
<p><strong>解决方案：</strong></p>
<ul>
<li><p>如果数据库中值为空，把空写入缓存即可。</p>
</li>
<li><p>也可以把所有的可能存在的key放入到一个大的Bitmap中，查询时通过该Bitmap过滤</p>
</li>
</ul>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存中大量数据同时到期，高并发下，所有请求都走向数据库</p>
<p><strong>解决方案：</strong></p>
<p>尽量不要把所有缓存都设置在同一时间过期, 通过加锁或者队列只允许一个线程查询数据库和写缓存, 其他线程等待.</p>
<p>通过加锁或者队列只允许一个线程查询数据库和写缓存，其他线程等待。</p>
<h2 id="热点缓存（缓存击穿）"><a href="#热点缓存（缓存击穿）" class="headerlink" title="热点缓存（缓存击穿）"></a>热点缓存（缓存击穿）</h2><p>双重检测锁解决热点缓存问题，需要加volatile防止指令重排</p>
<p>高并发下，一个热点缓存到期，然后去数据库中去取，当还没有放入缓存中时，大量请求过来</p>
<p><strong>解决方案：</strong></p>
<ul>
<li><strong>双重检测锁</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Integer count = redis.get(<span class="string">"key"</span>);</span><br><span class="line"><span class="keyword">if</span> (count == <span class="keyword">null</span>) &#123;</span><br><span class="line">  <span class="keyword">synchronized</span> &#123;</span><br><span class="line">    count = redis.get(<span class="string">"key"</span>);</span><br><span class="line">    <span class="keyword">if</span> (count == <span class="keyword">null</span>) &#123;</span><br><span class="line">      count = repo.getCount();</span><br><span class="line">      redis.put(<span class="string">"key"</span>, count);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ul>
<li>也可以用redis的setnx互斥锁进行判断</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (redis.setnx(lockKey, requestId, NX, PX) == <span class="number">1</span>) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="缓存双写一致性"><a href="#缓存双写一致性" class="headerlink" title="缓存双写一致性"></a><strong>缓存双写一致性</strong></h2><p><strong>解决方案：</strong></p>
<p>延时双删策略, 先更新数据库，再删缓存</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">  redis.delKey(key);</span><br><span class="line">  db.updateData(data);</span><br><span class="line">  <span class="comment">// 可以将以下两步作为异步处理</span></span><br><span class="line">  Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">  redis.delKey(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a><strong>Redis简介</strong></h2><p>Redis是一种用C语言开发的，高性能的，键值对key-value形式的<strong>noSql</strong>数据库</p>
<p>支持5种<strong>string</strong>, <strong>hash</strong>, <strong>set</strong>, <strong>list</strong>, 有序集合类型(<strong>sortedset</strong>, 简称zset)等数据类型</p>
<p>劣势就是存储的数据缺少结构化</p>
<p>应用场景：</p>
<ul>
<li><p>内存数据库（登录信息，购物车信息，用户浏览记录）</p>
</li>
<li><p>缓存信息</p>
</li>
<li><p>解决分布式架构中的session分离问题</p>
</li>
</ul>
<h2 id="redis常用命令"><a href="#redis常用命令" class="headerlink" title="redis常用命令"></a><strong>redis常用命令</strong></h2><ul>
<li><p>redis-server</p>
</li>
<li><p>redis-client</p>
</li>
<li><p>性能测试工具</p>
<p>redis-benchmark</p>
<p>redis-benchmark -q(Quiet. Just show query/sec values) -n(default 100000 requests)</p>
<p>-h <hostname>      Server hostname (default 127.0.0.1)</hostname></p>
<p> -p <port>          Server port (default 6379)</port></p>
<p> -s <socket>        Server socket (overrides host and port)</socket></p>
<p> -a <password>      Password for Redis Auth</password></p>
<p> -c <clients>       Number of parallel connections (default 50)</clients></p>
<p> -n <requests>      Total number of requests (default 100000)</requests></p>
<p> -d <size>          Data size of SET/GET value in bytes (default 2)</size></p>
<p> -dbnum <db>        SELECT the specified db number (default 0)</db></p>
<p> -k <boolean>       1=keep alive 0=reconnect (default 1)</boolean></p>
<p> -r <keyspacelen>   Use random keys for SET/GET/INCR, random values for SADD</keyspacelen></p>
<p>  Using this option the benchmark will expand the string <strong>rand_int</strong></p>
<p>  inside an argument with a 12 digits number in the specified range</p>
<p>  from 0 to keyspacelen-1. The substitution changes every time a command</p>
<p>  is executed. Default tests use this to hit random keys in the</p>
<p>  specified range.</p>
<p> -P <numreq>        Pipeline <numreq> requests. Default 1 (no pipeline).</numreq></numreq></p>
<p> -q                 Quiet. Just show query/sec values</p>
<p> –csv              Output in CSV format</p>
<p> -l                 Loop. Run the tests forever</p>
<p> -t <tests>         Only run the comma separated list of tests. The test</tests></p>
<p>​                    names are the same as the ones produced as output.</p>
<p> -I                 Idle mode. Just open N idle connections and wait.</p>
</li>
<li><p>redis-check-aof</p>
<p>aof文件检查的工具</p>
</li>
<li><p>redis-check-dump</p>
<p>rdb文件进行检查的工具</p>
</li>
<li><p>redis-sentinel</p>
<p>启动哨兵监控服务</p>
</li>
</ul>
<h2 id="redis数据类型及常用操作"><a href="#redis数据类型及常用操作" class="headerlink" title="redis数据类型及常用操作"></a>redis数据类型及常用操作</h2><ul>
<li><p><strong>string</strong></p>
<p>set key value, get key, getset key value, incr key(必须为整数), incrby key increment, decr key, decrby increment</p>
<p>setnx key value, append key value, strlen key, mset key1 value2 key2 value2…, <strong>mget</strong> key1, key2 …</p>
</li>
<li><p><strong>hash</strong>散列类型，如(people –&gt; name –&gt; “chris”)</p>
<p>字段的名只能用string</p>
<p>hset key field value, hget key field, hmset …, hsetnx key field value(同hset,但是如果field存在，则不执行任何操作),</p>
<p>hmget 批量取, hdel key, hincrby key field increment, hexists key field, hkeys key, hvals key, hlen key, hgetall key</p>
</li>
<li><p><strong>list</strong>类型(链表实现的)</p>
<p>lpush/rpush, lrange, lpop/rpop, llen, </p>
<p>lrem key count value</p>
<p>当count&gt;0时，从左边开始删，删除在count范围内，值为value的元素</p>
<p>当count&lt;0时，从右边开始删</p>
<p>当count=0时，删除所有值为value的元素</p>
<p>lindex, lset key index value, ltrip key start stop, linsert key before|after “specified value” value, rpoplpush,</p>
</li>
<li><p><strong>set</strong>类型</p>
<p>不重复且没有顺序(指放入和取出的顺序不一致)</p>
<p>sadd,srem key value, smembers key, sismember key value, sdiff A B(A - B), sinter A B(A ∩ B), sunion A B(A ∪ B),</p>
<p>scard key(获取元素个数),spop(从集合中随机选择一个元素弹出)</p>
</li>
<li><p><strong>zset</strong>类型（为每个元素都关联一个分数）</p>
<p>有序集合和list对比</p>
<p>相同点：两者都有序，两者都可以获得某一范围内的元素</p>
<p>区别：列表访问两边数据很快，访问中间数据很慢。有序集合都很快</p>
<p>有序列表可以调整元素位置，通过分数实现；</p>
<p>有序集合耗内存</p>
<p>zadd key score member, zrange/zrevrange key start stop [withscores],</p>
<p>zscore key,zrem, zrangebyscore key min max, zincrby key increment member, zcard key(当前集合中元素数量)</p>
<p>zcount key min max(指定分数范围内元素的个数), zremrangebyrank key start stop, zrank/zrevrank key member</p>
</li>
</ul>
<ul>
<li><p>通用命令</p>
<p>keys, del, exists, expire key, ttl key(剩余生存时间), persist key(清除生存时间), </p>
<p>pexpire key milliseconds(生存时间设置单位为毫秒), rname oldkey newkey, type key, </p>
</li>
</ul>
<h2 id="redis事务介绍-指一组命令的集合"><a href="#redis事务介绍-指一组命令的集合" class="headerlink" title="redis事务介绍(指一组命令的集合)"></a>redis事务介绍(指一组命令的集合)</h2><p>redis使用<strong>multi</strong>, <strong>exec</strong>, <strong>discard</strong>, <strong>watch</strong>, <strong>unwatch</strong>实现事务</p>
<p>redis不支持事务回滚</p>
<p>执行multi后，Redis会将命令逐个放入队列中，然后用exce执行这个队列中的命令</p>
<p>而watch是在multi之前，watch某个属性，表示我这个multi块中可能要修改该属性，如果multi块中的命令在未执行前有客户端修改了该请求，那么该multi块中的命令就会执行失败。</p>
<h2 id="redis持久化（指的是持久化到磁盘）"><a href="#redis持久化（指的是持久化到磁盘）" class="headerlink" title="redis持久化（指的是持久化到磁盘）"></a><strong>redis持久化</strong>（指的是<strong>持久化到磁盘</strong>）</h2><p>redis持久化的方式有两种，<strong>RDB</strong>和<strong>AOF</strong></p>
<h3 id="RDB-redis默认方式"><a href="#RDB-redis默认方式" class="headerlink" title="RDB(redis默认方式)"></a>RDB(redis默认方式)</h3><p>rdb是使用快照(snapshotting)的方式进行持久化的</p>
<h4 id="触发快照的时机"><a href="#触发快照的时机" class="headerlink" title="触发快照的时机"></a><strong>触发快照的时机</strong></h4><ul>
<li><p>符合自定义的快照规则</p>
</li>
<li><p>执行save或者bgsave命令</p>
<p><strong>注:</strong> save命令是阻塞的，执行bgsave时会fork出一个进程进行保存，非阻塞的</p>
</li>
<li><p>执行flushall命令</p>
<p><strong>注：</strong>线上一般要禁止掉flushall(删除所有数据库的所有 key),flushdb(删除当前数据库的所有key), keys *等命令</p>
<p>在redis配置文件中添加：</p>
<p>rename-command FLUSHALL “”  </p>
<p>rename-command FLUSHDB “”  </p>
<p>rename-command KEYS “”</p>
</li>
<li><p>执行主从复制操作</p>
</li>
</ul>
<p>redis获取所有数据库：</p>
<p>config get databases(默认有16个数据库，index从0开始)</p>
<p>select 0选择数据库</p>
<h4 id="快照规则-或的关系"><a href="#快照规则-或的关系" class="headerlink" title="快照规则(或的关系)"></a>快照规则(或的关系)</h4><p><strong>save 900 1</strong> <strong>“**</strong>15分钟内有1次修改就进行快照<strong>**”</strong></p>
<p><strong>save 300 10</strong> <strong>“**</strong>5分钟内有10次修改就进行快照<strong>**”</strong></p>
<p><strong>save 60 10000</strong> <strong>“**</strong>1分钟内有10000次修改就进行快照<strong>**”</strong></p>
<p>dir ./ 指定快照地址(rdb文件地址)</p>
<p>dbfilename dump.rdb</p>
<h4 id="快照过程"><a href="#快照过程" class="headerlink" title="快照过程"></a>快照过程</h4><ol>
<li><p><strong>Redis调用系统fork函数复制出一份当前进程的副本(子进程)</strong></p>
</li>
<li><p><strong>子进程开始将内存中的数据写入到硬盘中的临时文件</strong></p>
</li>
<li><p><strong>用临时文件替代旧的rdb文件(经过压缩的二进制文件)</strong></p>
</li>
</ol>
<h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul>
<li><p>缺点: 一旦Redis异常退出，就将丢失最后一次快照后更改的所有数据</p>
</li>
<li><p>优点: rdb可以最大化Redis的性能</p>
</li>
</ul>
<h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>AOF: 每执行一条更改，Redis就会将该命令写入AOF文件. 实际上是<strong>先写入到硬盘缓存，然后通过硬盘缓存刷新机制保存到文件。</strong></p>
<p><strong>appendfsync always</strong></p>
<p><strong>appendfsync everysec(默认)</strong></p>
<p><strong>appendfsync no(由系统进行sync)</strong></p>
<p>默认关闭，打开是appendonly yes</p>
<p>在数据量比较大的时候，频繁的写入和修改，aof文件会变得非常臃肿，所以我们可以设置重写规则：</p>
<ul>
<li><p>auto-aof-rewrite-min-size：64m</p>
</li>
<li><p>auto-aof-rewrite-percentage：100</p>
</li>
</ul>
<h3 id="RDB-和-AOF比较"><a href="#RDB-和-AOF比较" class="headerlink" title="RDB 和 AOF比较"></a>RDB 和 AOF比较</h3><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是<strong>fork一个子进程</strong>，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。</p>
<p>AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。</p>
<h3 id="数据库备份和灾难恢复"><a href="#数据库备份和灾难恢复" class="headerlink" title="数据库备份和灾难恢复"></a>数据库备份和灾难恢复</h3><p>定时生成RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。</p>
<p>Redis 支持同时开启 RDB 和 AOF,系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。</p>
<h3 id="RDB-和-AOF-我应该用哪一个"><a href="#RDB-和-AOF-我应该用哪一个" class="headerlink" title="RDB 和 AOF ,我应该用哪一个"></a>RDB 和 AOF ,我应该用哪一个</h3><p>如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久。</p>
<p>AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低 Redis 的性能，不知道你是否可以接受。</p>
<h2 id="redis主从复制"><a href="#redis主从复制" class="headerlink" title="redis主从复制"></a>redis主从复制</h2><ul>
<li><p>只需要在从服务器的配置文件中添加：</p>
<p>slaveof 192.168.1.123 6379</p>
</li>
<li><p>主从复制保证了即使有服务器宕机，也能保证对外提供服务。</p>
</li>
<li><p>当进行主从复制时，不会阻塞。</p>
</li>
<li><p>一个从服务器也可能是另一台服务器的主</p>
</li>
</ul>
<p>原理：</p>
<p><strong>分为全量同步和增量同步</strong></p>
<ul>
<li><strong>全量同步</strong>是当第一次从服务器连接上主服务器时进行的同步，在全量同步期间，主服务器还会有新的写操作过来，这时候主服务器会把这些操作放入到缓冲区。<ol>
<li>master创建快照并发送给slave(将此期间的写入放入缓冲区)</li>
<li>master向slave同步缓冲区的写操作命令</li>
<li>同步增量阶段</li>
</ol>
</li>
</ul>
<ul>
<li><p>增量同步是全量同步之后的一个正常操作的过程</p>
<p>master每执行一个写操作，都会将该命令发送到slave</p>
</li>
</ul>
<h2 id="redis哨兵机制"><a href="#redis哨兵机制" class="headerlink" title="redis哨兵机制"></a>redis哨兵机制</h2><ul>
<li><p>redis主从复制的缺点是当有Redis主服务器进行宕机时，不能进行动态的选举。需要<strong>使用Sentinel机制完成动态选举</strong>。</p>
</li>
<li><p>因此Sentinel进程的作用：监控master的状态（实际上也可以监控slave），在master宕机之后完成动态的选举。</p>
</li>
<li><p>如果有master或者slave宕机，可以通过脚本向管理员发送通知（短信或邮件）。即Monitoring 和 Notification.</p>
</li>
</ul>
<ul>
<li><p><strong>sentinel动态选举过程</strong>（Automatic failover）：</p>
<ol>
<li><p><strong>检测到master出现异常</strong></p>
</li>
<li><p><strong>将其中一个slave复制为新的master</strong></p>
</li>
<li><p><strong>当有slave请求master时</strong></p>
</li>
<li><p><strong>返回新的master地址</strong></p>
</li>
</ol>
<p><strong>注:</strong> master和slave的redis.conf，和sentinel.conf都会发生变化， </p>
</li>
<li><p><strong>sentinel故障分析过程</strong></p>
<ol>
<li>sentinel会以<strong>每秒1次的频率</strong>发送ping命令到Master, Slave 和 其他Sentinel</li>
<li>若回复ping命令超时（sentinel.conf文件中指定的down-after-milliseconds）,则该实例会被标记为<strong>SDOWN</strong>(主管下线)</li>
<li>如果有足够数量(sentinel.conf中指定的)的Sentinel都将该实例标记为SDOWN，则该实例变为<strong>ODOWN</strong></li>
</ol>
</li>
<li><p>监控的主机名称为master，地址和IP，当有2个quorum认为mymaster失联时，则标记为ODOWN</p>
<p>sentinel monitor mymaster 127.0.0.1 6379 2</p>
<p>注意：</p>
<ol>
<li><p>虽然没有写监控slave，但是slave是被自动检测的</p>
</li>
<li><p>虽然指定了ODOWN的数量，但是还是需要大多数的Sentinel同意来开启故障转移</p>
</li>
</ol>
</li>
</ul>
<h2 id="sentinel一些配置"><a href="#sentinel一些配置" class="headerlink" title="sentinel一些配置"></a>sentinel一些配置</h2><ul>
<li><p>port 26379(default)</p>
</li>
<li><p>dir /tmp(工作目录)</p>
</li>
<li><p>当实例开启了requirepass foobared,需要在sentinel.conf中添加如下配置</p>
<ul>
<li><p>sentinel auth-pass <master-name> <password></password></master-name></p>
</li>
<li><p>sentinel down-after-milliseconds <master-name> <milliseconds></milliseconds></master-name></p>
</li>
<li><p>sentinel parallel-syncs <master-name> <numreplicas> 当master发生故障时，最多有几个slave同时对master进行更新</numreplicas></master-name></p>
</li>
</ul>
</li>
<li><p>sentinel failover-timeout mymaster 180000（这个超时时间有4种用途）</p>
<ul>
<li><p>所有slave对新的master进行更新时所需的最大时间，如果超过这个时间，则parallel-syncs无效，变为一次只能有一个更新</p>
</li>
<li><p>同一个Sentinel对同一个master两次failover之间的间隔时间</p>
</li>
<li><p>取消一个正在failover的实例所允许的最大时间(取消的前提是配置文件还未发生变化)</p>
</li>
<li><p>slave从一个错误的master同步数据到纠正为从正确的master同步数据所需要的最大时间</p>
</li>
</ul>
</li>
<li><p>脚本</p>
<ul>
<li><p>脚本返回1，则会重试，默认重试10次</p>
</li>
<li><p>脚本返回值 &gt; 2,不重试</p>
</li>
<li><p>脚本执行中中断，则和返回1效果一样</p>
</li>
<li><p>当一个脚本执行超过60秒，则会被一个SIGKILL信号终止，然后重试</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>通知型脚本</p>
<p>sentinel notification-script mymaster /var/redis/notify.sh</p>
<p>当系统有sdown或者ODOWN时会向管理员发送短信或邮件，该通知接收两个参数，事件类型和事件描述</p>
<p>注：如果配置了该脚本，那么该脚本必须存在且是可执行的，否则无法启动Sentinel</p>
</li>
<li><p>客户端重新配置主节点参数脚本</p>
<p>sentinel client-reconfig-script <master-name> <script-path></script-path></master-name></p>
<p>当master发生改变，执行该脚本通知客户端主机的新地</p>
<p>这些参数将会被传递到该脚本：</p>
<p><master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port></to-port></to-ip></from-port></from-ip></state></role></master-name></p>
<p>state 一直是 failover</p>
<p>role 是 observer或者leader</p>
<p>from-:老的master的IP和端口号，to-:新的master的IP和端口号</p>
</li>
</ul>
<h2 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h2><h3 id="redis-集群保证了高可用"><a href="#redis-集群保证了高可用" class="headerlink" title="redis 集群保证了高可用"></a><strong>redis 集群保证了高可用</strong></h3><ul>
<li><p>Redis集群特点</p>
<p><strong>集群中的各个实例（节点）彼此互联，通过ping-pong机制</strong></p>
<ul>
<li><strong>节点失效判断(fail):</strong> <strong>需要集群中所有的master投票, 经过半数以上的节点检测失效时才生效</strong></li>
</ul>
</li>
<li><p>客户端与Redis节点是直连，不需要经过任何代理</p>
</li>
<li><p>Redis-cluster把所有物理节点映射到[0-16383]slot上，cluster负责维护node – slot – value</p>
<p>注：redis集群内置了<strong>16384</strong>个slot，当客户端保存一个key-value时，redis先对key使用<strong>crc16</strong>算法算出一个结果，然后把结果对16384取余，Redis会把16384个slot均等的分配到各个节点上。每个节点都包含了一个各个node的信息</p>
</li>
<li><p><strong>集群失效判断</strong></p>
<ul>
<li><p>如果集群任意master挂掉，且该master没有slave时。集群挂掉。因为16384个hash槽不完整</p>
</li>
<li><p>集群超过半数的master挂掉，不管是否有slave。</p>
</li>
</ul>
</li>
<li><p><strong><font color="#dd0000">注: 为什么是16384个槽?</font></strong></p>
<p><strong>(自我描述: redis对一个key进行crc16算法, 产生一个16位(bit)的hash值, 那么该算法可以产生65536个值, 但为什么不是65536个槽, 而是16384个槽呢? 原因有几点:</strong> </p>
<p><strong>1.</strong> <strong>与Redis的心跳机制有关, redis两个节点在发生心跳的时候, 消息头中包含如myslots[CLUSTER_SLOTS/8], 所以如果发送65536个这样的信息, 就需要65536 * 8 * 1024 = 8K, 太大, 浪费带宽;</strong> </p>
<p><strong>2.</strong> <strong>实际16384个槽已经足够用, 因为当redis的节点超过1000时, 整个集群的效率会非常低, 会造成网络拥堵. 因此作者建议不要超过1000个节点)</strong></p>
</li>
</ul>
<h3 id="客户端连接集群"><a href="#客户端连接集群" class="headerlink" title="客户端连接集群"></a>客户端连接集群</h3><ul>
<li><p>./redis-cli -h 127.0.0.1 -p 7001 -c</p>
</li>
<li><p>添加新的节点：</p>
<p>./redis-trib.rb add-node 127.0.0.1:7007 127.0.0.1:7001</p>
<p>./redis-trib.rb reshard 127.0.0.1:7001(连接上任一节点即可)</p>
<p>./redis-trib.rb add-node –slave –master-id 主节点id 新节点的IP和端口 旧节点ip和端口（集群中任一节点都可以）</p>
</li>
</ul>
<h2 id="redis实现分布式锁"><a href="#redis实现分布式锁" class="headerlink" title="redis实现分布式锁"></a>redis实现分布式锁</h2><ul>
<li><p>单应用</p>
<p>一般用synchronize，ReentrantLock实现锁</p>
</li>
<li><p>分布式</p>
<p>分布式锁注意事项：</p>
<ul>
<li><p>互斥性：即在任一时刻只有一个客户端能持有锁</p>
</li>
<li><p>同一性：加锁和解锁必须是同一客户端</p>
</li>
<li><p>可重入性：即使一个客户端没有主动解锁（崩溃等），也能保证后续其他客户端能加锁（超时时间）</p>
</li>
</ul>
</li>
<li><p>基于<strong>数据库的乐观锁</strong>实现分布式锁</p>
</li>
<li><p>zookeeper临时节点的分布式锁</p>
</li>
<li><p>基于<strong>Redis的分布式锁</strong></p>
<p>使用set key value [ex seconds] [px milliseconds] [NX|XX]</p>
<p>ex和px都表示过期时间，单位不一样</p>
<p>NX是在不存在时设置，XX是在存在时设置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">getLock</span><span class="params">(String lockKey, String requestId, <span class="keyword">int</span> expireTime)</span> </span>&#123;</span><br><span class="line">  String result = jedis.set(lockKey, requestId, <span class="string">"NX"</span>, <span class="string">"EX"</span>, expireTime);</span><br><span class="line">  <span class="keyword">return</span> <span class="string">"OK"</span>.equals(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>释放锁</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">releaseLock</span><span class="params">(String requestId, String lockKey)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (requestId.equals(jedis.get(lockKey)))  &#123;</span><br><span class="line">    jedis.del(lockKey);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="redis-过期策略"><a href="#redis-过期策略" class="headerlink" title="redis 过期策略"></a>redis 过期策略</h2><ul>
<li><p><strong>定期删除</strong>+ <strong>惰性删除</strong> + <strong>内存淘汰机制</strong></p>
<p><strong>定期删除</strong>: Redis默认是每隔100ms就随机抽取一些设置了过期时间的key. 假如redis中有100万个key, 都设置了过期时间,那么肯定不会每隔100毫秒就遍历100万个key然后删除过期了的key. <strong>当get某个key的时候, redis会检测该key有没有过期, 如果过期,就删除, 然后返回空.这就是惰性删除</strong>. 但是内存中如果有10万个key没有被访问到, 不可能让他们长期在内存中消耗内存, 这时候就需要走<strong>内存淘汰机制</strong></p>
<p>内存淘汰机制: </p>
<ul>
<li><p><strong>noeviction</strong>：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧</p>
</li>
<li><p><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，<strong>在键空间中</strong>，移除最近最少使用的key（这个是最常用的）</p>
</li>
<li><p><strong>allkeys-random</strong>：当内存不足以容纳新写入数据时，<strong>在键空间中</strong>，随机移除某个key，这个一般没人用吧</p>
</li>
<li><p><strong>volatile-lru</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，移除最近最少使用的key（这个一般不太合适）</p>
</li>
<li><p><strong>volatile-random</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，随机移除某个key</p>
</li>
<li><p><strong>volatile-ttl</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，有更早过期时间的key优先移除</p>
</li>
</ul>
</li>
</ul>
<h2 id="redis-cluster对mget的操作"><a href="#redis-cluster对mget的操作" class="headerlink" title="redis cluster对mget的操作"></a><strong>redis cluster对mget</strong>的操作</h2><p>Redis cluster不支持mget操作. 最初是facebook, 2010年使用memcache作缓存, 共有3000个节点. 发现节点太多, 连接频率下降. 继续增加节点, 并没有改善, 是因为IO的成本已经超过数据传输.</p>
<p>所以redis cluster也因此不支持mget操作.redis引入cluster模式后, 是将数据hash到<strong>16384</strong>个slot上, 每个node负责一部分slot.</p>
<p><strong>mget优化方案:</strong> </p>
<ol>
<li><p>n个key, 传统IO, 分别获取, 时间复杂度为O(n)</p>
</li>
<li><p>n个key, 通过Redis的hash算法可以得出各个key所对应的节点, 这样时间复杂度就位O(node.size())</p>
</li>
<li><p>在B方案的基础之上并发处理</p>
</li>
</ol>
<h2 id="redis的redlock"><a href="#redis的redlock" class="headerlink" title="redis的redlock"></a>redis的redlock</h2><ul>
<li><p><strong>redlock的前提是有N个redis的master, 这些节点之间没有主从复制, 或者其他集群协调机制.</strong></p>
</li>
<li><p>client从N个节点尝试获取锁, 只要有N/2 + 1个节点获取成功, 那么便获取成功; 如果最终获取失败, 客户端应该在所有的节点上进行解锁. </p>
</li>
<li><p>redlock的出发点是为了解决Redis集群环境下, 出现的分布式锁的问题(client1获取锁, master 宕机, slave变成master, client2获取到锁). 但是redlock的出现并没有解决这样的问题.</p>
</li>
</ul>
<p><strong><font color="#dd0000">Martin和Redis作者antirez之间的争辩:</font></strong></p>
<p>martin挑了两个缺点:</p>
<p>​    1. 对于提升效率的场景, redlock太重</p>
<p>​    2. 对于正确性要求极高的场景, redlock并不能保证正确性;</p>
<p><strong>问题:</strong> 在client1获取锁之后, 由于某种原因发生<strong>系统停顿</strong>, 锁过期, 然后client1执行操作; client2这时候也会拿到锁, 就会出现问题)</p>
<p><strong>问题:</strong> A, B, C, D, E 5个redis节点,如果C的时间走得快, client1拿到锁(A, B, C), C节点先过期, client2又拿到了(C, D, E)这样就出问题了;</p>
<p>所以Redis从根本上来说是AP, 而分布式锁是要求CP的.</p>
<h2 id="redis各种数据类型的数据结构"><a href="#redis各种数据类型的数据结构" class="headerlink" title="redis各种数据类型的数据结构"></a>redis各种数据类型的数据结构</h2><h3 id="Redis的底层数据结构"><a href="#Redis的底层数据结构" class="headerlink" title="Redis的底层数据结构"></a>Redis的底层数据结构</h3><ul>
<li>简单动态字符串sds(Simple Dynamic String)</li>
<li>双端链表(LinkedList)</li>
<li>字典(Map)</li>
<li>跳跃表(SkipList)</li>
</ul>
<h3 id="redis各种数据类型使用的数据结构"><a href="#redis各种数据类型使用的数据结构" class="headerlink" title="redis各种数据类型使用的数据结构"></a>redis各种数据类型使用的数据结构</h3><ul>
<li><strong>String</strong>, <strong>SDS</strong>(simple dynamic string) 简单动态字符串, 包含len(字符串长度), free(空闲的字节数量), buf(字节数组,存储数据)</li>
<li><strong>List</strong>, 使用<strong>压缩列表</strong>(数据集比较少的时候, 列表中单个数据小于64字节或者列表中数据个数少于512个)和<strong>双向循环链表</strong>, 包含pre, next, value</li>
<li><strong>hash</strong>, 使用<strong>压缩列表</strong>(键和值的大小小于64字节, 列表中键值对个数小于512个)和<strong>散列表</strong></li>
<li><strong>Set</strong>, <strong>有序数组</strong>(个数不超过512)和<strong>散列表</strong></li>
<li><strong>Zset</strong>, <strong>压缩列表</strong>(数据小于64字节或者个数小于128个)和<strong>跳跃表</strong></li>
</ul>
<h3 id="用ziplist代替key-value减少80-内存占用的案例"><a href="#用ziplist代替key-value减少80-内存占用的案例" class="headerlink" title="用ziplist代替key-value减少80%内存占用的案例"></a>用ziplist代替key-value减少80%内存占用的案例</h3><p>​    <strong>背景:</strong> 因业务原因, 需要大量存储key-value数据, key和value都为string, 如果存储1千万条数据，占用了redis共计1.17G的内存. 当数据量变成1个亿时，实测大约占用8个G. 但是修改为key(int), value 为ziplist时, 内存占用为123M, 减少了85%.</p>
<p>​    <strong>步骤:</strong></p>
<ol>
<li><p>要将1千万个键值对, 放到N个bucket中, 但是为了防止ziplist变为hashtable, 每个bucket不能超过512个键值对, 1千万 / 512 = 19531. 将所有key hash到所有bucket中, 但由于hash函数的不确定性, 可能出现不均等分配, 可以分配25000个bucket, 或者30000个bucket.</p>
</li>
<li><p>选用hash算法, 决定将key放到哪个bucket. 这里我们采用高效而且均衡的知名算法crc32. 通过获取原有md5(key)的crc32后, 再对bucket的数量进行取余.</p>
</li>
<li><p>第2步确定了外层的key, 内部的field我们选用bkdr哈希算法.</p>
<p>​    </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">BKDRHash</span><span class="params">(String str)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> seed = <span class="number">131</span>;</span><br><span class="line">  <span class="keyword">int</span> hash = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; str.length; i++) &#123;</span><br><span class="line">    hash = (hash * seed) + str.charAt(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> (hash &amp; <span class="number">0X7FFFFFFF</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<p>装入1000万条数据, 内存降低了85%; </p>
<p>查询测试, 查100万条数据, 对比查询速度:</p>
<p> key-value耗时：10653、10790、11318、9900、11270、11029毫秒</p>
<p> hash-field耗时：12042、11349、11126、11355、11168毫秒</p>
</li>
</ol>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/19/kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/19/kafka/" class="post-title-link" itemprop="url">kafka</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-19 16:07:27" itemprop="dateCreated datePublished" datetime="2020-01-19T16:07:27+08:00">2020-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-20 11:19:08" itemprop="dateModified" datetime="2020-01-20T11:19:08+08:00">2020-01-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="kafka应用场景"><a href="#kafka应用场景" class="headerlink" title="kafka应用场景"></a>kafka应用场景</h2><p>kafka是分布式消息系统，具有高吞吐量，可容错的发布-订阅消息系统。</p>
<p>应用场景:</p>
<ul>
<li><p>用户活动追踪</p>
</li>
<li><p>日志聚合</p>
</li>
<li><p>限流削峰</p>
</li>
</ul>
<p>高吞吐率实现：</p>
<ul>
<li>顺序读写</li>
<li>零拷贝</li>
<li>批量发送</li>
<li>消息压缩</li>
</ul>
<h2 id="kafka基本概念"><a href="#kafka基本概念" class="headerlink" title="kafka基本概念"></a>kafka基本概念</h2><ul>
<li><p><strong>Topic</strong>，相当于消息的一个主题，标签</p>
</li>
<li><p><strong>Partition</strong>，一个topic可以有多个partition，一个partition对应系统上的一个到多个目录。一个topic的partition数量应该是broker的整数倍。 </p>
</li>
<li><p><strong>segment</strong>，一个partition有多个segment组成，每个segment文件大小相等</p>
<p>文件由.log 和 .index文件组成，.index是存放.log文件中消息的索引</p>
<p>查看log文件：</p>
<p>bin/kafka-run-class.sh kafka.tools.DumpLogSegments –files /tmp/kafka-logs-3/test-0/00000000000000000000.log –print-data-log </p>
</li>
<li><p><strong>broker</strong>，kafka集群中的每个节点称为一个broker</p>
</li>
<li><p><strong>producer</strong>，消息的生产者</p>
</li>
<li><p><strong>consumer</strong>，消息的消费者，</p>
<ul>
<li><p>一个消费者可以消费多个topic的消息，</p>
</li>
<li><p>一个消费者可以消费一个topic的多个partition的消息</p>
</li>
<li><p>一个partition允许多个消费者同时消费</p>
</li>
</ul>
</li>
<li><p><strong>consumer group</strong>，消费者组，kafka保证一个消息只会被一个组中的某一个kafka消费。</p>
</li>
<li><p><strong>replicas of partition</strong>, 分区副本，为了防止消息丢失而创建的分区的备份。</p>
</li>
<li><p><strong>partition leader</strong>，每个partition有多个副本，而读写操作只能发生在leader上</p>
</li>
<li><p><strong>partition follower</strong>，所有follower都需要从leader同步消息,Leader与follower是主备关系，而非主从关系。</p>
</li>
<li><p><strong>ISR</strong>， In-Sync-Replicas,是指副本同步列表</p>
<ul>
<li><p><strong>AR</strong>，Assigned Replicas,在最初没有leader时，ISR=AR</p>
</li>
<li><p><strong>OSR</strong>，Outof-Sync-Replicas</p>
</li>
<li><p><strong>AR</strong> = ISR + OSR + Leader，ISR是存放在zk中的</p>
</li>
</ul>
</li>
<li><p><strong>offset</strong>,每条消息都有一个当前Partition下唯一的64字节的offset</p>
</li>
<li><p><strong>broker controller</strong>， kafka集群中有一个broker会被选举出来，作为controller，负责管理整个集群的partition和replicas的状态</p>
<p>只有broker controller会向zookeeper中注册watcher</p>
</li>
<li><p><strong>脑裂：（Brain Split）</strong>，由于某种原因导致高可用集群中出现了两个master。zk的watcher机制及分布式锁会引发master的假死，从而导致脑裂。</p>
</li>
<li><p><strong>HW（High Water-Mark）与 LEO（Log End Offset）</strong></p>
<ul>
<li><p>HW 是kafka消费者可以消费到的最高partition的偏移量，HW保证了kafka集群中消息的一致性。</p>
</li>
<li><p>LEO 是日志消息最后的偏移量</p>
</li>
<li><p>对于partition leader中新写入的消息，是不能立即被消费者消费的，只有当ISR中所有的partition follower消费之后，更新HW，写入ISR，此时消息才能被消费者消费。HW的更新速度取决于那个性能最差的broker</p>
</li>
</ul>
</li>
<li><p><strong>zookeeper</strong></p>
<ul>
<li><p>zookeeper负则broker controller的选举。</p>
</li>
<li><p>partition leader是由 broker controller负则选举的</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>Coordinator</strong></p>
<p>coordinator是用来管理消费者组的，是运行在每个broker上的group coordinator进程，主要负则offset的位移管理和rebalance,一个coordinator可以管理多个消费者组 </p>
</li>
<li><p><strong>rebalance</strong></p>
<p>当消费者组中的消费者数量发生变化，或者topic中的partition数量发生变化，会导致partition的重新分配，这个过程叫做Rebalance.</p>
<p>rebalance可以给系统带来高可用性和伸缩性，但是<strong>在Rebalance期间，消费者是无法读取消息的</strong>，因此要避免不必要的Rebalance</p>
</li>
</ul>
<p>  <strong>引发Rebalance的情形：</strong></p>
<ul>
<li>消费者组中添加消费者</li>
<li>消费者取消订阅，关闭或崩溃</li>
<li>向一个topic中添加新的partition</li>
<li>当有broker挂了</li>
</ul>
<ul>
<li><p><strong>offset commit</strong></p>
<p>消费者从partition中取出一批消息放入buffer中进行消费，在规定的时间内（seession.timeout.ms）消费完消息后，会自动将其消费的commit提交给broker，broker可以判断哪些消息有被消费过，若在规定时间内没有消费完毕，其是不会提交offset的, 可以避免在Rebalance时重复消费。</p>
</li>
</ul>
<p><strong>注:</strong> 从kafka0.9开始，offset保存在brokers中，__consumers-offsets</p>
<h2 id="kafka工作原理与流程"><a href="#kafka工作原理与流程" class="headerlink" title="kafka工作原理与流程"></a><strong>kafka工作原理与流程</strong></h2><ul>
<li><p><strong>消息路由</strong>（即写入的消息放入到哪个partition）</p>
<ul>
<li><p>若指定了partition,则写入指定的partition</p>
</li>
<li><p>若未指定partition，但指定了key，则对key取hash然后对partition个数取余</p>
</li>
<li><p>partition和key均为指定，则根据轮询算法选出一个partition</p>
</li>
</ul>
</li>
<li><p><strong>消息写入算法</strong>（即消息写入的过程）</p>
<ol>
<li><p>producer从zookeeper中获取partition的leader</p>
</li>
<li><p>producer将消息发送给leader</p>
</li>
<li><p>leader将消息写入到本地log</p>
</li>
<li><p>ISR中的follower从leader中pull消息，写入本地log后向leader发送ack</p>
</li>
<li><p>leader收到所有follower的ack后，增加HW并向producer发送ACK</p>
</li>
</ol>
</li>
<li><p><strong>HW截断机制</strong></p>
<p>HW截断机制保证了partition的leader宕机之后，leader与follower之间的数据不一致。</p>
<p>两种情况：</p>
<ul>
<li>当leader宕机之后，选举出一个新的leader，为了防止leader和follower的数据不一致，此时所有的FOLLOWER都要将数据截断到HW位置, 然后再同步新leader中的数据</li>
<li>当leader从宕机中恢复后，发现新的leader中和自己的数据不一致，此时宕机的leader会将数据截断到宕机之前的HW位置，然后同步新的leader中的数据</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>消息发送的可靠性机制</strong></p>
<p>producer向kafka发送消息时，可以选择需要的可靠性级别，通过request.required.acks参数的值进行设置</p>
<ul>
<li><p>0值（异步发送）</p>
<p>不需要kafka反馈成功ack，效率最高，可靠性最低，因为消息可能会丢失。消息丢失的情况：</p>
<ul>
<li><p>在传输途中丢失，网络原因</p>
</li>
<li><p>在broker中丢失，消息发到broker时是先放入到buffer，当broker的buffer满足将消息写入到partition时（容量到，时间到，或数量到）</p>
</li>
<li><p>在buffer正要写入到partition但还未写入时，新的消息又来了，可能丢失。</p>
</li>
<li><p>顺序与生产顺序不一致（网络原因）</p>
</li>
</ul>
</li>
<li><p>1值（同步发送）</p>
<p>消息发送成功后，立即向生产者返回ack(未等待ISR中的follower同步消息)</p>
<p>当leader收到新的消息后还未同步，leader宕机，新选举出的leader是不知道该信息存在的，造成消息的丢失。</p>
</li>
<li><p>-1值（同步发送）</p>
<p>leader收到消息，并向ISR列表中的所有FOLLOWER都同步了消息之后再向producer返回ack.</p>
<p>该模式消息几乎不会丢失，但有可能出现消息重复接收的情况。</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>消费者消费过程解析</strong><ul>
<li>消费者消费订阅的topic, broker controller会为消费者指定消息的partition，并将partition的offset发送给消费者</li>
<li>当有生产者向该partition中生产消息时，broker会将消息推送给消费者</li>
<li>消费者收到推送，消费该消息</li>
<li>消费者消费完该消息，向broker发送消费成功反馈</li>
<li>broker收到消费者反馈，更新partition中的offset</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>partition的leader选举范围</strong></p>
<p>partition的leader宕机后，broker controller从ISR中选举一个FOLLOWER成为新的leader，但若ISR中所有的FOLLOWER都宕机了, 则可以通过<strong>unclean.leader.election.enable</strong>的取值来设置leader的选举范围</p>
</li>
<li><p><strong>unclean.leader.election.enable</strong></p>
<ul>
<li><p>false</p>
<p>必须等到副本中有FOLLOWER活过来再进行新的选举，可靠性有保证，但可用性低。</p>
</li>
<li><p>true</p>
<p>选择任何一个没有宕机的FOLLOWER，但该FOLLOWER可能不在ISR中（OSR）。</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>重复消费及解决方案</strong></p>
<ul>
<li><p>同一个consumer重复消费</p>
<p>有一个消费的超时时间，auto.commit.interval.ms，在该时间内没有消费完消息，此时consumer会向broker提交一个异常，但是由于没有消费完，</p>
<p>所以没有向partition提交offset，所以再次消费时还是消费的同样的消息。</p>
</li>
<li><p>不同的consumer重复消费</p>
<p>当consumer消费了某条消息后，提交了offset，但是由于网络等原因，没有在session.timeout.ms中将该offset发送给broker，broker认为该consumer宕机，然后rebalnce,这个partition又被分配给了其他消费者，由于该partition的offset没有被修改，所以会再次被消费</p>
</li>
</ul>
</li>
</ul>
<p>​        <strong>解决方案</strong></p>
<p>​            增加auto.commit.interval.ms</p>
<p>​            设置enable.auto.commit为false，将kafka自动提交offset该为手动提交</p>
<p>​            手动提交分为：<strong>同步提交</strong>，<strong>异步提交</strong>，<strong>同异步联合提交</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SyncAsyncManualConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"KafkaConsumerTest"</span>, <span class="keyword">false</span>);</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        String brokers = <span class="string">"kafkaOS1:9092,kafkaOS2:9092,kafkaOS3:9092"</span>;</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers);</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"cityGro11"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"false"</span>);</span><br><span class="line">        <span class="comment">// properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");</span></span><br><span class="line">        <span class="comment">// 设置一次提交的offset个数</span></span><br><span class="line">        properties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">10</span>);</span><br><span class="line">        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                <span class="string">"org.apache.kafka.common.serialization.IntegerDeserializer"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">               <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="keyword">this</span>.consumer = <span class="keyword">new</span> KafkaConsumer&lt;Integer, String&gt;(properties);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 指定要消费的主题</span></span><br><span class="line">  consumer.subscribe(Collections.singletonList(<span class="string">"cities"</span>));</span><br><span class="line">  ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord record : records) &#123;</span><br><span class="line">    System.out.print(<span class="string">"topic = "</span> + record.topic());</span><br><span class="line">    System.out.print(<span class="string">" partition = "</span> + record.partition());</span><br><span class="line">    System.out.print(<span class="string">" key = "</span> + record.key());</span><br><span class="line">    System.out.println(<span class="string">" value = "</span> + record.value());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 带回调功能的手动异步提交</span></span><br><span class="line">      consumer.commitAsync((offsets, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">          System.out.print(<span class="string">"提交失败，offsets = "</span> + offsets);</span><br><span class="line">          System.out.println(<span class="string">"，exception = "</span> + e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">      <span class="comment">// 同步提交</span></span><br><span class="line">      consumer.commitSync();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="kafka如何保证数据不丢失"><a href="#kafka如何保证数据不丢失" class="headerlink" title="kafka如何保证数据不丢失"></a><strong>kafka如何保证数据不丢失</strong></h2><ul>
<li><p>生产者数据的不丢失</p>
<ul>
<li><p>同步模式</p>
<p>​    request.required.acks = 1(follower 未同步数据)/-1(follower同步完数据,但效率低)</p>
</li>
<li><p>异步模式</p>
<p>通过设置时间阈值和消息数量阈值, 并且设置为阻塞模式</p>
<p>producer.type=async </p>
<p>request.required.acks=1 </p>
<p>queue.buffering.max.ms=5000 </p>
<p>queue.buffering.max.messages=10000 </p>
<p>queue.enqueue.timeout.ms = -1 </p>
<p>batch.num.messages=200</p>
</li>
</ul>
</li>
<li><p>消费者的数据不丢失</p>
<p>通过offset commit 来保证数据的不丢失，kafka自己记录了每次消费的offset数值，下次继续消费的时候，接着上次的offset进行消费即可</p>
</li>
</ul>
<h2 id="kafka性能到底好在哪儿"><a href="#kafka性能到底好在哪儿" class="headerlink" title="kafka性能到底好在哪儿"></a>kafka性能到底好在哪儿</h2><ul>
<li><p>采用<strong>BIO</strong>, 虽AIO性能更好, 但是编程难度较大</p>
</li>
<li><p>高性能的网络设计</p>
</li>
<li><p>顺序写</p>
<p> 客户端写数据—-&gt; 操作系统缓存 —-&gt; 写入磁盘(<strong>顺序写</strong>), 如果磁盘的个数和转数跟得上的话, 都快赶上写内存的速度了.</p>
</li>
<li><p>跳表, 稀松索引, 零拷贝</p>
</li>
</ul>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/16/rabbitMQ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/16/rabbitMQ/" class="post-title-link" itemprop="url">rabbitMQ</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-16 16:53:13" itemprop="dateCreated datePublished" datetime="2020-01-16T16:53:13+08:00">2020-01-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-19 16:01:05" itemprop="dateModified" datetime="2020-01-19T16:01:05+08:00">2020-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="rabbitMQ简介"><a href="#rabbitMQ简介" class="headerlink" title="rabbitMQ简介"></a>rabbitMQ简介</h2><ul>
<li><p>按照官网的说法, rabbitMQ就像是一个邮局. 由Post Box, Post office, Post man组成</p>
</li>
<li><p>控制管理台: <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDoxNTY3Mi8=" title="http://localhost:15672/">http://localhost:15672/<i class="fa fa-external-link"></i></span></p>
</li>
<li><p>4种交换机: <strong>Fanout</strong> Exchange, <strong>Direct</strong> Exchange, <strong>Topic</strong> Exchange, <strong>Headers</strong> Exchange</p>
</li>
</ul>
<h2 id="图解rabbitMQ"><a href="#图解rabbitMQ" class="headerlink" title="图解rabbitMQ"></a>图解rabbitMQ</h2><p>Message has a routing key and queue has binded a routing key, if they are matched by the rules then the message will be sent to this queue.</p>
<p><img src="/2020/01/16/rabbitMQ/RabbitMQ.png" alt="图解rabbit MQ"></p>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/15/MessageQueue/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/15/MessageQueue/" class="post-title-link" itemprop="url">消息队列</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-15 15:40:20" itemprop="dateCreated datePublished" datetime="2020-01-15T15:40:20+08:00">2020-01-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-19 16:03:13" itemprop="dateModified" datetime="2020-01-19T16:03:13+08:00">2020-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="为什么使用消息队列"><a href="#为什么使用消息队列" class="headerlink" title="为什么使用消息队列"></a>为什么使用消息队列</h2><h3 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h3><p>​    譬如签到送积分, 签到和送积分是两个操作. 签到产生了很重要的数据, 它可以把该消息发送到MQ. 然后积分系统需要该数据, 从MQ中直接获取即可. 这样签到系统就做到了和积分系统解耦. 不必担心积分系统挂了怎么办, 是不是需要重试等. 这些都可以在积分系统内部自己实现. 再者, 如果以后另外一套系统也需要该签到数据, 直接从MQ中获取即可, 实际上与签到系统已无关系.</p>
<h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>​    当做到解耦后, 实际异步就是自然而然的事情. 如果签到只需要1ms, 而送积分, 或者其他操作需要500ms, 那不可能等所有操作完成之后再去返回数据给用户. 这样就做到了异步.</p>
<h3 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h3><p>​    削峰是指当并发访问高峰期, 通过MQ达到限流的目的, 从而减少对数据库MySQL的压力.</p>
<h2 id="消息队列有什么优点和缺点"><a href="#消息队列有什么优点和缺点" class="headerlink" title="消息队列有什么优点和缺点"></a>消息队列有什么优点和缺点</h2><p><strong>优点</strong>就是第一点所提到的<strong>解耦</strong>, <strong>异步</strong>, <strong>削峰</strong></p>
<p>缺点: </p>
<ul>
<li><p>系统可用性降低(当然有办法保证高可用), 相对而言</p>
</li>
<li><p>系统复杂度提高(这是引入新技术之后的必然结果), 因为随之而来的问题就是该技术本身的问题: 如何保证消息没有重复消费, 如何保证消息不丢失, 如何保证消息的顺序性等等</p>
</li>
<li><p>数据一致性问题(也可以归为系统复杂度提高的问题), 可以解决</p>
</li>
<li><p>如何保证消息的高可用</p>
</li>
<li><p>消息传递路径更长, 延时会增加</p>
</li>
<li><p>上游无法知道下游的执行结果(很致命)</p>
</li>
</ul>
<h2 id="MQ适合使用的场景"><a href="#MQ适合使用的场景" class="headerlink" title="MQ适合使用的场景"></a>MQ适合使用的场景</h2><ul>
<li><p>数据驱动的任务依赖. 如晚上执行的定时任务, task1, task2, task3, task2依赖task1, task3依赖task2</p>
</li>
<li><p>上游不关心执行结果. 如签到送积分, 修改/添加/删除数据要添加审计日志</p>
</li>
<li><p>上游关注执行结果,但执行时间很长. 如通过支付宝转账, 第三方把转账结果通过网关放入MQ, MQ再来通知用户 </p>
</li>
</ul>
<h2 id="MQ不适合使用场景"><a href="#MQ不适合使用场景" class="headerlink" title="MQ不适合使用场景"></a>MQ不适合使用场景</h2><p>上游需要依赖下游的执行结果, 如登录, 不能把登录成功的消息放入MQ</p>
<h2 id="各种MQ如何选择"><a href="#各种MQ如何选择" class="headerlink" title="各种MQ如何选择"></a>各种MQ如何选择</h2><ul>
<li><p>社区活跃度,: RabbitMQ和kafka &gt; rocketMQ(阿里) &gt; ActiveMQ</p>
</li>
<li><p>性能: kafka, rocketMQ &gt; RabbitMQ &gt; ActiveMQ</p>
</li>
<li><p>功能完善性: rocketMQ, rabbitMQ, activeMQ &gt; kafka</p>
</li>
</ul>
<p>所以中小公司, 没有自主研发能力的选择RabbitMQ, </p>
<p>如果大数据公司做实时计算, 日志采集建议用kafka</p>
<p>大公司可以使用rocketMQ, 因为用Java开发, 有问题自己可修改</p>
<h2 id="如何保证消息不被重复消费-消费的幂等性"><a href="#如何保证消息不被重复消费-消费的幂等性" class="headerlink" title="如何保证消息不被重复消费(消费的幂等性)"></a>如何保证消息不被重复消费(消费的幂等性)</h2><p><strong>重复消费的场景:</strong></p>
<ul>
<li>同一个消费者重复消费</li>
</ul>
<p>指定时间内未消费完, 没有提交offset, 下次消费时重复消费</p>
<ul>
<li>不同的消费者重复消费</li>
</ul>
<p>consumer消费完之后, 没有提交offset或者未提交成功offset, consumer挂了, 该消息被分配给了其他consumer, 导致重复消费</p>
<p><strong>问题解决:</strong></p>
<ul>
<li><p>设置超时时间</p>
</li>
<li><p>关闭自动提交, 改为手动提交, 提交之前检测数据库中是否有该消费过的数据</p>
</li>
</ul>
<h2 id="如何保证消息的可靠性传输-消息丢失问题"><a href="#如何保证消息的可靠性传输-消息丢失问题" class="headerlink" title="如何保证消息的可靠性传输(消息丢失问题)"></a>如何保证消息的可靠性传输(消息丢失问题)</h2><p><strong>消息丢失场景:</strong></p>
<ul>
<li><p>生产者丢失数据</p>
</li>
<li><p>MQ丢失数据</p>
</li>
<li><p>消费者丢失数据</p>
</li>
</ul>
<p><strong>问题解决:</strong></p>
<p>​    生产者要等MQ返回ack之后才认为该消息发送成功*<em>, *</em>否则重试.(异步发送ack或nack信号, 不用等待)</p>
<ul>
<li><p>RabbitMQ是通过持久化和confirm机制(即生产者要等MQ返回ack); </p>
</li>
<li><p>kafaka通过设置参数:</p>
<p>replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本</p>
<p>min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower</p>
<p>acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了</p>
<p>retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试</p>
</li>
<li><p>rabbitMQ和kafka关闭自动ack, 改为手动ack, 如果该消费者未提交ack, 那么MQ会分配其他消费者消费该消息;</p>
</li>
</ul>
<h2 id="如何保证消息的顺序性"><a href="#如何保证消息的顺序性" class="headerlink" title="如何保证消息的顺序性"></a>如何保证消息的顺序性</h2><p><strong>场景:</strong> 如现在需要做一个mysql binlog的同步系统, 如果原始顺序是create, update, delete, 如果是无序的就有可能变成delete, create, update, 这样就出错了.</p>
<p>RabbitMQ场景: 生产者放入顺序是data1, data2, data3, 因为有多个消费者, 所以有可能顺序会乱</p>
<p>kafka场景: 生产者放入data1, data2, data3,生产者指定key,可以让这3条数据放入一个partition,一个partition是由一个消费者来消费的, 但是消费者端肯定会起多个线程来消费消息, 多个线程并发, 顺序就可能乱掉了.</p>
<p><strong>解决:</strong></p>
<p>实际上所有的顺序一致性都是: 生产者  —&gt;  MQ server   —&gt; 消费者, 只要消息在生产者, MQ server和消费者中间是顺序一致的, 就能保证消息的顺序一致. 保证生产者消息放入MQ server中的时候, 相同key的数据只放入一个queue(或partition), 然后消费的时候由一个消费者来消费, 就能保证消息的顺序一致. 譬如下单, 扣款, 发货, 这三个消息, 只要保证同一个订单内部的一致性就可以. 不同订单没有因果关系, 所以可以不用保证不同订单之间的顺序一致.</p>
<h2 id="如何保证MQ的高可用"><a href="#如何保证MQ的高可用" class="headerlink" title="如何保证MQ的高可用"></a><strong>如何保证MQ的高可用</strong></h2><ul>
<li><p>rabbitMQ 通过镜像集群模式. 即创建的queue, 无论是元数据还是queue里的消息, 都会存在于多个实例上. 就是说每个rabbitMQ节点都有这个queue的一个完整镜像.包含queue的全部数据, 每次写消息到queue的时候, 都会自动把消息同步到多个queue上.</p>
</li>
<li><p>kafka天然的分布式消息队列, kafka集群由多个broker组成, 一个topic可以有多个partition, 每个partition存在于不同的broker上. 每个broker上只存partition的一部分数据. 每个partition都会有副本存在于其他broker上, 这样即使有broker宕机, 也可以重新选举出一个partition作为leader, 继续支持读写.</p>
</li>
</ul>
<h2 id="如何处理消息的延时以及过期失效问题"><a href="#如何处理消息的延时以及过期失效问题" class="headerlink" title="如何处理消息的延时以及过期失效问题"></a><strong>如何处理消息的延时以及过期失效问题</strong></h2><p>​    因为MQ,如rabbitMQ有ttl, 如果数据积压, 超过TTL时间不处理, 会直接丢掉.</p>
<p>​    这时候, 只能把这些数据进行批量重导, 重新灌入mq里面</p>
<h2 id="消息队列满了怎么处理"><a href="#消息队列满了怎么处理" class="headerlink" title="消息队列满了怎么处理"></a><strong>消息队列满了怎么处理</strong></h2><p>临时写个程序, 不做耗时操作, 操作一条废弃一条. 到系统并发量小的时候,譬如晚上12点的时候, 再做批量重导.</p>
<h2 id="有百万条消息积压几小时-怎么处理"><a href="#有百万条消息积压几小时-怎么处理" class="headerlink" title="有百万条消息积压几小时,怎么处理"></a>有百万条消息积压几小时,怎么处理</h2><p><strong>场景:</strong> MQ里积压了上千万条数据</p>
<p><strong>解决:</strong> </p>
<ol>
<li><p>查清楚是什么原因导致消息积压: consumer程序bug; consumer的消费速度落后于producer的生产速度;</p>
</li>
<li><p>如果仅是consumer的的消费速度落后于生产速度的话, 考虑扩容即可</p>
</li>
<li><p>若是consumer故障, 修复consumer, 并将其停掉</p>
</li>
<li><p>重新创建一个容量大的topic, 比如partition是原来的10倍</p>
</li>
<li><p>编写一个新的consumer, 消费原来积压的队列, 该consumer不做任何耗时的操作,将消息均匀的写入新创建的队列里</p>
</li>
<li><p>将修复好的consumer部署到原来10倍机器上消费队列</p>
</li>
<li><p>消息积压解决后, 恢复原有架构</p>
</li>
</ol>
<h2 id="如何自己设计一个消息队列"><a href="#如何自己设计一个消息队列" class="headerlink" title="如何自己设计一个消息队列"></a>如何自己设计一个消息队列</h2><p>首先要理解kafka的原理</p>
<ul>
<li><p>broker –&gt; topic –&gt; partition, 如果资源不够用了, 就给topic增加partition, 提高吞吐量</p>
</li>
<li><p>mq要顺序落盘</p>
</li>
<li><p>高可用partition 副本, leader, broker</p>
</li>
<li><p>解决数据0丢失</p>
</li>
</ul>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/14/DistributeTransaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Shang">
      <meta itemprop="description" content="Java, Architect">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Architect">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/01/14/DistributeTransaction/" class="post-title-link" itemprop="url">分布式事务</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-01-14 14:00:03" itemprop="dateCreated datePublished" datetime="2020-01-14T14:00:03+08:00">2020-01-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-19 16:02:32" itemprop="dateModified" datetime="2020-01-19T16:02:32+08:00">2020-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="什么是分布式事务？"><a href="#什么是分布式事务？" class="headerlink" title="什么是分布式事务？"></a>什么是分布式事务？</h2><p>简单的说，就是一次大操作由不同小操作组成，这些小操作分布在不同服务器上，分布式事务需要保证这些小操作要么全部成功，要么全部失败.</p>
<h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a><strong>两阶段提交</strong></h2><p>两阶段提交简称2PC(two phase commitment)</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>TM(Transaction Manager) 事务管理器</li>
<li>RM(Resource Manager) 资源管理器</li>
</ul>
<h3 id="两阶段提交-1"><a href="#两阶段提交-1" class="headerlink" title="两阶段提交:"></a>两阶段提交:</h3><ul>
<li><p>在第一阶段, 资源管理器向事务管理器汇报各自事务的状态;</p>
</li>
<li><p>在第二阶段, 事务管理器根据资源管理器汇报的状态来来确定是回滚还是提交;</p>
</li>
</ul>
<p><strong><font color="#dd0000">注: 两阶段提交方案锁定资源时间长，对性能影响很大，基本不适合解决微服务事务问题.</font></strong></p>
<p>​      <strong><font color="#dd0000">两阶段提交协议是基于XA规范, 阻塞, 属于刚性事务</font></strong></p>
<p>​    数据库实现(XA, MySQL和Oracle都支持)</p>
<p>​    xa_start, xa_end, xa_prepare, xa_commit, xa_rollback</p>
<h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a><strong>TCC</strong></h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>​    TCC(Try Confirm Cancel), 是2PC的一种改进</p>
<p>​    事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后事务协调器会根据try接口返回情况，决定调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。</p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>TCC方案让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。 当然TCC方案也有不足之处，集中表现在以下两个方面：</p>
<ul>
<li><p>对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。</p>
</li>
<li><p>实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。</p>
</li>
</ul>
<h2 id="基于消息的最终一致性方案"><a href="#基于消息的最终一致性方案" class="headerlink" title="基于消息的最终一致性方案"></a><strong>基于消息的最终一致性方案</strong></h2><p>消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。</p>
<p>消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。</p>
<h2 id="阿里的GTS"><a href="#阿里的GTS" class="headerlink" title="阿里的GTS"></a><strong>阿里的GTS</strong></h2><p>Fescar（Fast &amp; EaSy Commit And Rollback), 升级后为: Seata(Simple Extensible Autonomous Transaction Architecture) </p>
<h3 id="seata-工作原理"><a href="#seata-工作原理" class="headerlink" title="seata 工作原理"></a>seata 工作原理</h3><p>下面是来自于<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NlYXRhL3NlYXRh" title="https://github.com/seata/seata">seata<i class="fa fa-external-link"></i></span>的工作原理图</p>
<p><img src="/2020/01/14/DistributeTransaction/seata-procedure.png" alt="seata flow chart"></p>
<ul>
<li><strong>Transaction Coordinator(TC):</strong> 用来协调全局事务和各个分支事务的状态, 驱动全局事务和各个分支事务的回滚或提交</li>
<li><strong>Transaction Manager(TM):</strong> 定义了事务的范围(一般是业务层), 用来<strong>开启/提交/回滚</strong>一个整体事务</li>
<li><strong>Resource Manager(RM):</strong> 管理分支事务, 与TC进行协调注册分支事务并且汇报分支事务的状态, 驱动分支事务的提交或回滚</li>
</ul>
<h3 id="seata管理分布式事务的生命周期"><a href="#seata管理分布式事务的生命周期" class="headerlink" title="seata管理分布式事务的生命周期"></a>seata管理分布式事务的生命周期</h3><pre><code>1. TM向TC请求开启一个新的全局事务, TC生成一个代表该全局事务的XID
 2. XID在整个microservice的整个调用链中都可见
 3. RM把本地事务向TC注册为XID全局事务的一个分支
 4. TM向TC请求XID全局事务的提交或回滚
 5. TC驱动所有XID全局事务的提交或回滚</code></pre><h2 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a><strong>数据一致性</strong></h2><h3 id="数据不一致产生的原因"><a href="#数据不一致产生的原因" class="headerlink" title="数据不一致产生的原因"></a>数据不一致产生的原因</h3><ul>
<li><p>不同的DB(用户有UserDB, 商品有Product DB)</p>
</li>
<li><p>DB和缓存(商品有Product DB 和 Product Cache)</p>
</li>
</ul>
<p>问题1: 如果把下单操作和把下单消息放到MQ的操作放到一个try-catch块中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// 下单</span></span><br><span class="line">  orderService.createOrder();</span><br><span class="line">  <span class="comment">// 发送消息到MQ</span></span><br><span class="line">  msgClient.sendMsg(orderId);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>发送消息是网络操作, 网络操作一般会有3中结果: success, fail, timeout. Success 和 fail都相对好处理, 但是<strong>timeout</strong>是不知道消息发送成功还是失败的.所以这种操作是<strong>不合理</strong>的. </p>
<p><strong>解决方法: 一般会先把下单成功的消息放入DB中, 然后从DB中取数据放入MQ</strong></p>
<p><strong>分布式缓存和数据库的一致性4步骤:</strong></p>
<ul>
<li><p>先更新数据库, 然后delete缓存</p>
</li>
<li><p>延时双删</p>
</li>
<li><p>设置缓存失效时间</p>
</li>
<li><p>记录日志, 脚本定期修正</p>
</li>
</ul>
<h2 id="柔性分布式事务-saga"><a href="#柔性分布式事务-saga" class="headerlink" title="柔性分布式事务(saga)"></a>柔性分布式事务(saga)</h2><p>Saga模式是现实中可行的方案，采用事务补偿机制。每个本地事务都存储一个副本，如果出现失败，则利用补偿机制回滚。</p>
<p>TCC模型和saga模型</p>
<p>TCC(Try, Confirm, Cancel), 以A向B账户转账为例, 分为汇款服务和收款服务</p>
<h3 id="saga-汇款服务"><a href="#saga-汇款服务" class="headerlink" title="saga-汇款服务:"></a><strong>saga-汇款服务:</strong></h3><ul>
<li><p>Try:</p>
<ol>
<li><p>检查A账户的有效性, 账户状态,是否冻结等, </p>
</li>
<li><p>账户余额是否充足</p>
</li>
<li><p>从A账户中扣减500元, 并将状态置为转账中</p>
</li>
<li><p>预留扣减资源, 将A往B账户转账这个事件存入MQ(或DB)中</p>
</li>
</ol>
</li>
<li><p>Confirm:</p>
<p>不做任何操作</p>
</li>
<li><p>Cancel:</p>
<ol>
<li><p>A账户增加500元</p>
</li>
<li><p>从MQ(或DB)中,释放扣减资源</p>
</li>
</ol>
</li>
</ul>
<h3 id="saga-收款服务"><a href="#saga-收款服务" class="headerlink" title="saga-收款服务:"></a><strong>saga-收款服务:</strong></h3><ul>
<li><p>Try:</p>
<p>检查B账户的有效性</p>
</li>
<li><p>Confirm:</p>
<ol>
<li><p>读MQ(或DB), B账户增加500元</p>
</li>
<li><p>从MQ(或DB)释放扣减资源</p>
</li>
</ol>
</li>
<li><p>Cancel:</p>
<p>不做任何操作</p>
</li>
</ul>
<p><strong>saga模型:</strong></p>
<p>把一个长事务拆分成多个短事务(本地事务), 每个事务都有对应的执行模块和补偿模块(对应TCC中的Confirm 和 Cancel)</p>
<ul>
<li><p>当任意一个本地事务出错, 就根据本地事务的补偿方法恢复之前的事务, 达到事务的最终一致性.</p>
</li>
<li><p>当最后一个本地事务失败时, 整个事务就失败, 不需要补偿. 所以针对N个本地事务, 只有对应N - 1个事务补偿</p>
</li>
</ul>
<p><strong>saga vs TCC</strong></p>
<p>​    区别在于TCC多了一个Try(<strong>预操作</strong>), 每次都会预扣减资源. saga虽然也有Try操作, 但是只是做一些检测操作</p>
<p><strong>saga 时序图</strong></p>
<p><img src="/2020/01/14/DistributeTransaction/saga-sequence-chart.png" alt="saga sequence chart"></p>
<p> <strong>TCC时序图</strong></p>
<p><img src="/2020/01/14/DistributeTransaction/TCC-sequence-chart.png" alt="tcc sequence chart"></p>
<p><strong><font color="#dd0000">刚性事务vs 柔性事务</font></strong></p>
<table>
<thead>
<tr>
<th></th>
<th><strong>刚性事务(XA模型)</strong></th>
<th><strong>柔性事务</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>实际项目中有无应用场景</strong></td>
<td><strong>无</strong></td>
<td><strong>有</strong></td>
</tr>
<tr>
<td><strong>回滚</strong></td>
<td><strong>支持</strong></td>
<td><strong>通过补偿支持</strong></td>
</tr>
<tr>
<td><strong>一致性</strong></td>
<td><strong>强一致性</strong></td>
<td><strong>最终一致性</strong></td>
</tr>
<tr>
<td><strong>隔离性</strong></td>
<td><strong>原生支持</strong></td>
<td><strong>实现资源锁定接口(如信用卡预授权)</strong></td>
</tr>
<tr>
<td><strong>并发性能</strong></td>
<td><strong>低, 严重衰退(锁定资源时间太久)</strong></td>
<td><strong>略微衰退</strong></td>
</tr>
<tr>
<td><strong>适合场景</strong></td>
<td><strong>短事务,并发较低</strong></td>
<td><strong>长事务, 高并发</strong></td>
</tr>
</tbody></table>
<h2 id="redis做分布式锁的问题"><a href="#redis做分布式锁的问题" class="headerlink" title="redis做分布式锁的问题"></a><strong>redis做分布式锁的问题</strong></h2><p><strong>SET lock_key random_value NX PX 5000</strong></p>
<ul>
<li><p><strong>锁没有办法严格保证唯一</strong>, 如使用master-slave模式, 当线程A通过setnx(orderId,…)拿到锁, 执行操作, 此时master挂掉, slave变为master, 原有的锁记录丢失. 线程B这时可以拿到锁, 就出现问题</p>
</li>
<li><p><strong>Redis锁存在租约问题</strong>,  如果操作执行时间超过了锁的有效期, 那么线程B同样会拿到锁 </p>
</li>
</ul>
<p><strong>注: redis从本质上说是AP模型, 只保证可用. 如果需要用分布式锁, 必须是CP模型, 需要保证一致性.etcd可以保证.</strong></p>
<p><img src="/2020/01/14/DistributeTransaction/distribute-transaction-consistent.png" alt="consistent"> </p>
<h2 id="分布式缓存的高可用"><a href="#分布式缓存的高可用" class="headerlink" title="分布式缓存的高可用"></a><strong>分布式缓存的高可用</strong></h2><p>缓存不可用, 查询数据库,</p>
<p>做好评估:  缓存宕机, 评估数据库压力持续更新(注)</p>
<h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chris Shang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Chris Shang</p>
  <div class="site-description" itemprop="description">Java, Architect</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL01yU2hhbmc=" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;MrShang"><i class="fa fa-fw fa-github"></i>GitHub</span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveGFpbC5jb20=" title="E-Mail → mailto:shchaoshuai@foxail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chris Shang</span>
</div>
  <div class="powered-by">Powered by <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <span class="exturl theme-link" data-url="aHR0cHM6Ly9tdXNlLnRoZW1lLW5leHQub3Jn">NexT.Muse</span> v7.7.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  

  

</body>
</html>
