<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Architect</title>
  
  <subtitle>The steps you take don&#39;t need to be big. They just need to take you in the right direction.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-01-20T08:08:05.629Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Chris Shang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>redis</title>
    <link href="http://yoursite.com/2020/01/20/redis/"/>
    <id>http://yoursite.com/2020/01/20/redis/</id>
    <published>2020-01-20T07:04:45.000Z</published>
    <updated>2020-01-20T08:08:05.629Z</updated>
    
    <content type="html"><![CDATA[<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>高并发下查询一个值，缓存中没有，数据库中也没有，布隆过滤器</p><p><strong>解决方案：</strong></p><ul><li><p>如果数据库中值为空，把空写入缓存即可。</p></li><li><p>也可以把所有的可能存在的key放入到一个大的Bitmap中，查询时通过该Bitmap过滤</p></li></ul><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存中大量数据同时到期，高并发下，所有请求都走向数据库</p><p><strong>解决方案：</strong></p><p>尽量不要把所有缓存都设置在同一时间过期, 通过加锁或者队列只允许一个线程查询数据库和写缓存, 其他线程等待.</p><p>通过加锁或者队列只允许一个线程查询数据库和写缓存，其他线程等待。</p><h2 id="热点缓存（缓存击穿）"><a href="#热点缓存（缓存击穿）" class="headerlink" title="热点缓存（缓存击穿）"></a>热点缓存（缓存击穿）</h2><p>双重检测锁解决热点缓存问题，需要加volatile防止指令重排</p><p>高并发下，一个热点缓存到期，然后去数据库中去取，当还没有放入缓存中时，大量请求过来</p><p><strong>解决方案：</strong></p><ul><li><strong>双重检测锁</strong></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Integer count = redis.get(<span class="string">"key"</span>);</span><br><span class="line"><span class="keyword">if</span> (count == <span class="keyword">null</span>) &#123;</span><br><span class="line">  <span class="keyword">synchronized</span> &#123;</span><br><span class="line">    count = redis.get(<span class="string">"key"</span>);</span><br><span class="line">    <span class="keyword">if</span> (count == <span class="keyword">null</span>) &#123;</span><br><span class="line">      count = repo.getCount();</span><br><span class="line">      redis.put(<span class="string">"key"</span>, count);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>也可以用redis的setnx互斥锁进行判断</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (redis.setnx(lockKey, requestId, NX, PX) == <span class="number">1</span>) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="缓存双写一致性"><a href="#缓存双写一致性" class="headerlink" title="缓存双写一致性"></a><strong>缓存双写一致性</strong></h2><p><strong>解决方案：</strong></p><p>延时双删策略, 先更新数据库，再删缓存</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(String key,Object data)</span></span>&#123;</span><br><span class="line">  redis.delKey(key);</span><br><span class="line">  db.updateData(data);</span><br><span class="line">  <span class="comment">// 可以将以下两步作为异步处理</span></span><br><span class="line">  Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">  redis.delKey(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a><strong>Redis简介</strong></h2><p>Redis是一种用C语言开发的，高性能的，键值对key-value形式的<strong>noSql</strong>数据库</p><p>支持5种<strong>string</strong>, <strong>hash</strong>, <strong>set</strong>, <strong>list</strong>, 有序集合类型(<strong>sortedset</strong>, 简称zset)等数据类型</p><p>劣势就是存储的数据缺少结构化</p><p>应用场景：</p><ul><li><p>内存数据库（登录信息，购物车信息，用户浏览记录）</p></li><li><p>缓存信息</p></li><li><p>解决分布式架构中的session分离问题</p></li></ul><h2 id="redis常用命令"><a href="#redis常用命令" class="headerlink" title="redis常用命令"></a><strong>redis常用命令</strong></h2><ul><li><p>redis-server</p></li><li><p>redis-client</p></li><li><p>性能测试工具</p><p>redis-benchmark</p><p>redis-benchmark -q(Quiet. Just show query/sec values) -n(default 100000 requests)</p><p>-h <hostname>      Server hostname (default 127.0.0.1)</hostname></p><p> -p <port>          Server port (default 6379)</port></p><p> -s <socket>        Server socket (overrides host and port)</socket></p><p> -a <password>      Password for Redis Auth</password></p><p> -c <clients>       Number of parallel connections (default 50)</clients></p><p> -n <requests>      Total number of requests (default 100000)</requests></p><p> -d <size>          Data size of SET/GET value in bytes (default 2)</size></p><p> -dbnum <db>        SELECT the specified db number (default 0)</db></p><p> -k <boolean>       1=keep alive 0=reconnect (default 1)</boolean></p><p> -r <keyspacelen>   Use random keys for SET/GET/INCR, random values for SADD</keyspacelen></p><p>  Using this option the benchmark will expand the string <strong>rand_int</strong></p><p>  inside an argument with a 12 digits number in the specified range</p><p>  from 0 to keyspacelen-1. The substitution changes every time a command</p><p>  is executed. Default tests use this to hit random keys in the</p><p>  specified range.</p><p> -P <numreq>        Pipeline <numreq> requests. Default 1 (no pipeline).</numreq></numreq></p><p> -q                 Quiet. Just show query/sec values</p><p> –csv              Output in CSV format</p><p> -l                 Loop. Run the tests forever</p><p> -t <tests>         Only run the comma separated list of tests. The test</tests></p><p>​                    names are the same as the ones produced as output.</p><p> -I                 Idle mode. Just open N idle connections and wait.</p></li><li><p>redis-check-aof</p><p>aof文件检查的工具</p></li><li><p>redis-check-dump</p><p>rdb文件进行检查的工具</p></li><li><p>redis-sentinel</p><p>启动哨兵监控服务</p></li></ul><h2 id="redis数据类型及常用操作"><a href="#redis数据类型及常用操作" class="headerlink" title="redis数据类型及常用操作"></a>redis数据类型及常用操作</h2><ul><li><p><strong>string</strong></p><p>set key value, get key, getset key value, incr key(必须为整数), incrby key increment, decr key, decrby increment</p><p>setnx key value, append key value, strlen key, mset key1 value2 key2 value2…, <strong>mget</strong> key1, key2 …</p></li><li><p><strong>hash</strong>散列类型，如(people –&gt; name –&gt; “chris”)</p><p>字段的名只能用string</p><p>hset key field value, hget key field, hmset …, hsetnx key field value(同hset,但是如果field存在，则不执行任何操作),</p><p>hmget 批量取, hdel key, hincrby key field increment, hexists key field, hkeys key, hvals key, hlen key, hgetall key</p></li><li><p><strong>list</strong>类型(链表实现的)</p><p>lpush/rpush, lrange, lpop/rpop, llen, </p><p>lrem key count value</p><p>当count&gt;0时，从左边开始删，删除在count范围内，值为value的元素</p><p>当count&lt;0时，从右边开始删</p><p>当count=0时，删除所有值为value的元素</p><p>lindex, lset key index value, ltrip key start stop, linsert key before|after “specified value” value, rpoplpush,</p></li><li><p><strong>set</strong>类型</p><p>不重复且没有顺序(指放入和取出的顺序不一致)</p><p>sadd,srem key value, smembers key, sismember key value, sdiff A B(A - B), sinter A B(A ∩ B), sunion A B(A ∪ B),</p><p>scard key(获取元素个数),spop(从集合中随机选择一个元素弹出)</p></li><li><p><strong>zset</strong>类型（为每个元素都关联一个分数）</p><p>有序集合和list对比</p><p>相同点：两者都有序，两者都可以获得某一范围内的元素</p><p>区别：列表访问两边数据很快，访问中间数据很慢。有序集合都很快</p><p>有序列表可以调整元素位置，通过分数实现；</p><p>有序集合耗内存</p><p>zadd key score member, zrange/zrevrange key start stop [withscores],</p><p>zscore key,zrem, zrangebyscore key min max, zincrby key increment member, zcard key(当前集合中元素数量)</p><p>zcount key min max(指定分数范围内元素的个数), zremrangebyrank key start stop, zrank/zrevrank key member</p></li></ul><ul><li><p>通用命令</p><p>keys, del, exists, expire key, ttl key(剩余生存时间), persist key(清除生存时间), </p><p>pexpire key milliseconds(生存时间设置单位为毫秒), rname oldkey newkey, type key, </p></li></ul><h2 id="redis事务介绍-指一组命令的集合"><a href="#redis事务介绍-指一组命令的集合" class="headerlink" title="redis事务介绍(指一组命令的集合)"></a>redis事务介绍(指一组命令的集合)</h2><p>redis使用<strong>multi</strong>, <strong>exec</strong>, <strong>discard</strong>, <strong>watch</strong>, <strong>unwatch</strong>实现事务</p><p>redis不支持事务回滚</p><p>执行multi后，Redis会将命令逐个放入队列中，然后用exce执行这个队列中的命令</p><p>而watch是在multi之前，watch某个属性，表示我这个multi块中可能要修改该属性，如果multi块中的命令在未执行前有客户端修改了该请求，那么该multi块中的命令就会执行失败。</p><h2 id="redis持久化（指的是持久化到磁盘）"><a href="#redis持久化（指的是持久化到磁盘）" class="headerlink" title="redis持久化（指的是持久化到磁盘）"></a><strong>redis持久化</strong>（指的是<strong>持久化到磁盘</strong>）</h2><p>redis持久化的方式有两种，<strong>RDB</strong>和<strong>AOF</strong></p><h3 id="RDB-redis默认方式"><a href="#RDB-redis默认方式" class="headerlink" title="RDB(redis默认方式)"></a>RDB(redis默认方式)</h3><p>rdb是使用快照(snapshotting)的方式进行持久化的</p><h4 id="触发快照的时机"><a href="#触发快照的时机" class="headerlink" title="触发快照的时机"></a><strong>触发快照的时机</strong></h4><ul><li><p>符合自定义的快照规则</p></li><li><p>执行save或者bgsave命令</p><p><strong>注:</strong> save命令是阻塞的，执行bgsave时会fork出一个进程进行保存，非阻塞的</p></li><li><p>执行flushall命令</p><p><strong>注：</strong>线上一般要禁止掉flushall(删除所有数据库的所有 key),flushdb(删除当前数据库的所有key), keys *等命令</p><p>在redis配置文件中添加：</p><p>rename-command FLUSHALL “”  </p><p>rename-command FLUSHDB “”  </p><p>rename-command KEYS “”</p></li><li><p>执行主从复制操作</p></li></ul><p>redis获取所有数据库：</p><p>config get databases(默认有16个数据库，index从0开始)</p><p>select 0选择数据库</p><h4 id="快照规则-或的关系"><a href="#快照规则-或的关系" class="headerlink" title="快照规则(或的关系)"></a>快照规则(或的关系)</h4><p><strong>save 900 1</strong> <strong>“**</strong>15分钟内有1次修改就进行快照<strong>**”</strong></p><p><strong>save 300 10</strong> <strong>“**</strong>5分钟内有10次修改就进行快照<strong>**”</strong></p><p><strong>save 60 10000</strong> <strong>“**</strong>1分钟内有10000次修改就进行快照<strong>**”</strong></p><p>dir ./ 指定快照地址(rdb文件地址)</p><p>dbfilename dump.rdb</p><h4 id="快照过程"><a href="#快照过程" class="headerlink" title="快照过程"></a>快照过程</h4><ol><li><p><strong>Redis调用系统fork函数复制出一份当前进程的副本(子进程)</strong></p></li><li><p><strong>子进程开始将内存中的数据写入到硬盘中的临时文件</strong></p></li><li><p><strong>用临时文件替代旧的rdb文件(经过压缩的二进制文件)</strong></p></li></ol><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul><li><p>缺点: 一旦Redis异常退出，就将丢失最后一次快照后更改的所有数据</p></li><li><p>优点: rdb可以最大化Redis的性能</p></li></ul><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><p>AOF: 每执行一条更改，Redis就会将该命令写入AOF文件. 实际上是<strong>先写入到硬盘缓存，然后通过硬盘缓存刷新机制保存到文件。</strong></p><p><strong>appendfsync always</strong></p><p><strong>appendfsync everysec(默认)</strong></p><p><strong>appendfsync no(由系统进行sync)</strong></p><p>默认关闭，打开是appendonly yes</p><p>在数据量比较大的时候，频繁的写入和修改，aof文件会变得非常臃肿，所以我们可以设置重写规则：</p><ul><li><p>auto-aof-rewrite-min-size：64m</p></li><li><p>auto-aof-rewrite-percentage：100</p></li></ul><h3 id="RDB-和-AOF比较"><a href="#RDB-和-AOF比较" class="headerlink" title="RDB 和 AOF比较"></a>RDB 和 AOF比较</h3><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是<strong>fork一个子进程</strong>，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。</p><p>AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。</p><h3 id="数据库备份和灾难恢复"><a href="#数据库备份和灾难恢复" class="headerlink" title="数据库备份和灾难恢复"></a>数据库备份和灾难恢复</h3><p>定时生成RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。</p><p>Redis 支持同时开启 RDB 和 AOF,系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。</p><h3 id="RDB-和-AOF-我应该用哪一个"><a href="#RDB-和-AOF-我应该用哪一个" class="headerlink" title="RDB 和 AOF ,我应该用哪一个"></a>RDB 和 AOF ,我应该用哪一个</h3><p>如果你非常关心你的数据,但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久。</p><p>AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低 Redis 的性能，不知道你是否可以接受。</p><h2 id="redis主从复制"><a href="#redis主从复制" class="headerlink" title="redis主从复制"></a>redis主从复制</h2><ul><li><p>只需要在从服务器的配置文件中添加：</p><p>slaveof 192.168.1.123 6379</p></li><li><p>主从复制保证了即使有服务器宕机，也能保证对外提供服务。</p></li><li><p>当进行主从复制时，不会阻塞。</p></li><li><p>一个从服务器也可能是另一台服务器的主</p></li></ul><p>原理：</p><p><strong>分为全量同步和增量同步</strong></p><ul><li><strong>全量同步</strong>是当第一次从服务器连接上主服务器时进行的同步，在全量同步期间，主服务器还会有新的写操作过来，这时候主服务器会把这些操作放入到缓冲区。<ol><li>master创建快照并发送给slave(将此期间的写入放入缓冲区)</li><li>master向slave同步缓冲区的写操作命令</li><li>同步增量阶段</li></ol></li></ul><ul><li><p>增量同步是全量同步之后的一个正常操作的过程</p><p>master每执行一个写操作，都会将该命令发送到slave</p></li></ul><h2 id="redis哨兵机制"><a href="#redis哨兵机制" class="headerlink" title="redis哨兵机制"></a>redis哨兵机制</h2><ul><li><p>redis主从复制的缺点是当有Redis主服务器进行宕机时，不能进行动态的选举。需要<strong>使用Sentinel机制完成动态选举</strong>。</p></li><li><p>因此Sentinel进程的作用：监控master的状态（实际上也可以监控slave），在master宕机之后完成动态的选举。</p></li><li><p>如果有master或者slave宕机，可以通过脚本向管理员发送通知（短信或邮件）。即Monitoring 和 Notification.</p></li></ul><ul><li><p><strong>sentinel动态选举过程</strong>（Automatic failover）：</p><ol><li><p><strong>检测到master出现异常</strong></p></li><li><p><strong>将其中一个slave复制为新的master</strong></p></li><li><p><strong>当有slave请求master时</strong></p></li><li><p><strong>返回新的master地址</strong></p></li></ol><p><strong>注:</strong> master和slave的redis.conf，和sentinel.conf都会发生变化， </p></li><li><p><strong>sentinel故障分析过程</strong></p><ol><li>sentinel会以<strong>每秒1次的频率</strong>发送ping命令到Master, Slave 和 其他Sentinel</li><li>若回复ping命令超时（sentinel.conf文件中指定的down-after-milliseconds）,则该实例会被标记为<strong>SDOWN</strong>(主管下线)</li><li>如果有足够数量(sentinel.conf中指定的)的Sentinel都将该实例标记为SDOWN，则该实例变为<strong>ODOWN</strong></li></ol></li><li><p>监控的主机名称为master，地址和IP，当有2个quorum认为mymaster失联时，则标记为ODOWN</p><p>sentinel monitor mymaster 127.0.0.1 6379 2</p><p>注意：</p><ol><li><p>虽然没有写监控slave，但是slave是被自动检测的</p></li><li><p>虽然指定了ODOWN的数量，但是还是需要大多数的Sentinel同意来开启故障转移</p></li></ol></li></ul><h2 id="sentinel一些配置"><a href="#sentinel一些配置" class="headerlink" title="sentinel一些配置"></a>sentinel一些配置</h2><ul><li><p>port 26379(default)</p></li><li><p>dir /tmp(工作目录)</p></li><li><p>当实例开启了requirepass foobared,需要在sentinel.conf中添加如下配置</p><ul><li><p>sentinel auth-pass <master-name> <password></password></master-name></p></li><li><p>sentinel down-after-milliseconds <master-name> <milliseconds></milliseconds></master-name></p></li><li><p>sentinel parallel-syncs <master-name> <numreplicas> 当master发生故障时，最多有几个slave同时对master进行更新</numreplicas></master-name></p></li></ul></li><li><p>sentinel failover-timeout mymaster 180000（这个超时时间有4种用途）</p><ul><li><p>所有slave对新的master进行更新时所需的最大时间，如果超过这个时间，则parallel-syncs无效，变为一次只能有一个更新</p></li><li><p>同一个Sentinel对同一个master两次failover之间的间隔时间</p></li><li><p>取消一个正在failover的实例所允许的最大时间(取消的前提是配置文件还未发生变化)</p></li><li><p>slave从一个错误的master同步数据到纠正为从正确的master同步数据所需要的最大时间</p></li></ul></li><li><p>脚本</p><ul><li><p>脚本返回1，则会重试，默认重试10次</p></li><li><p>脚本返回值 &gt; 2,不重试</p></li><li><p>脚本执行中中断，则和返回1效果一样</p></li><li><p>当一个脚本执行超过60秒，则会被一个SIGKILL信号终止，然后重试</p></li></ul></li></ul><ul><li><p>通知型脚本</p><p>sentinel notification-script mymaster /var/redis/notify.sh</p><p>当系统有sdown或者ODOWN时会向管理员发送短信或邮件，该通知接收两个参数，事件类型和事件描述</p><p>注：如果配置了该脚本，那么该脚本必须存在且是可执行的，否则无法启动Sentinel</p></li><li><p>客户端重新配置主节点参数脚本</p><p>sentinel client-reconfig-script <master-name> <script-path></script-path></master-name></p><p>当master发生改变，执行该脚本通知客户端主机的新地</p><p>这些参数将会被传递到该脚本：</p><p><master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port></to-port></to-ip></from-port></from-ip></state></role></master-name></p><p>state 一直是 failover</p><p>role 是 observer或者leader</p><p>from-:老的master的IP和端口号，to-:新的master的IP和端口号</p></li></ul><h2 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h2><h3 id="redis-集群保证了高可用"><a href="#redis-集群保证了高可用" class="headerlink" title="redis 集群保证了高可用"></a><strong>redis 集群保证了高可用</strong></h3><ul><li><p>Redis集群特点</p><p><strong>集群中的各个实例（节点）彼此互联，通过ping-pong机制</strong></p><ul><li><strong>节点失效判断(fail):</strong> <strong>需要集群中所有的master投票, 经过半数以上的节点检测失效时才生效</strong></li></ul></li><li><p>客户端与Redis节点是直连，不需要经过任何代理</p></li><li><p>Redis-cluster把所有物理节点映射到[0-16383]slot上，cluster负责维护node – slot – value</p><p>注：redis集群内置了<strong>16384</strong>个slot，当客户端保存一个key-value时，redis先对key使用<strong>crc16</strong>算法算出一个结果，然后把结果对16384取余，Redis会把16384个slot均等的分配到各个节点上。每个节点都包含了一个各个node的信息</p></li><li><p><strong>集群失效判断</strong></p><ul><li><p>如果集群任意master挂掉，且该master没有slave时。集群挂掉。因为16384个hash槽不完整</p></li><li><p>集群超过半数的master挂掉，不管是否有slave。</p></li></ul></li><li><p><strong><font color="#dd0000">注: 为什么是16384个槽?</font></strong></p><p><strong>(自我描述: redis对一个key进行crc16算法, 产生一个16位(bit)的hash值, 那么该算法可以产生65536个值, 但为什么不是65536个槽, 而是16384个槽呢? 原因有几点:</strong> </p><p><strong>1.</strong> <strong>与Redis的心跳机制有关, redis两个节点在发生心跳的时候, 消息头中包含如myslots[CLUSTER_SLOTS/8], 所以如果发送65536个这样的信息, 就需要65536 * 8 * 1024 = 8K, 太大, 浪费带宽;</strong> </p><p><strong>2.</strong> <strong>实际16384个槽已经足够用, 因为当redis的节点超过1000时, 整个集群的效率会非常低, 会造成网络拥堵. 因此作者建议不要超过1000个节点)</strong></p></li></ul><h3 id="客户端连接集群"><a href="#客户端连接集群" class="headerlink" title="客户端连接集群"></a>客户端连接集群</h3><ul><li><p>./redis-cli -h 127.0.0.1 -p 7001 -c</p></li><li><p>添加新的节点：</p><p>./redis-trib.rb add-node 127.0.0.1:7007 127.0.0.1:7001</p><p>./redis-trib.rb reshard 127.0.0.1:7001(连接上任一节点即可)</p><p>./redis-trib.rb add-node –slave –master-id 主节点id 新节点的IP和端口 旧节点ip和端口（集群中任一节点都可以）</p></li></ul><h2 id="redis实现分布式锁"><a href="#redis实现分布式锁" class="headerlink" title="redis实现分布式锁"></a>redis实现分布式锁</h2><ul><li><p>单应用</p><p>一般用synchronize，ReentrantLock实现锁</p></li><li><p>分布式</p><p>分布式锁注意事项：</p><ul><li><p>互斥性：即在任一时刻只有一个客户端能持有锁</p></li><li><p>同一性：加锁和解锁必须是同一客户端</p></li><li><p>可重入性：即使一个客户端没有主动解锁（崩溃等），也能保证后续其他客户端能加锁（超时时间）</p></li></ul></li><li><p>基于<strong>数据库的乐观锁</strong>实现分布式锁</p></li><li><p>zookeeper临时节点的分布式锁</p></li><li><p>基于<strong>Redis的分布式锁</strong></p><p>使用set key value [ex seconds] [px milliseconds] [NX|XX]</p><p>ex和px都表示过期时间，单位不一样</p><p>NX是在不存在时设置，XX是在存在时设置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">getLock</span><span class="params">(String lockKey, String requestId, <span class="keyword">int</span> expireTime)</span> </span>&#123;</span><br><span class="line">  String result = jedis.set(lockKey, requestId, <span class="string">"NX"</span>, <span class="string">"EX"</span>, expireTime);</span><br><span class="line">  <span class="keyword">return</span> <span class="string">"OK"</span>.equals(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>释放锁</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">releaseLock</span><span class="params">(String requestId, String lockKey)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (requestId.equals(jedis.get(lockKey)))  &#123;</span><br><span class="line">    jedis.del(lockKey);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="redis-过期策略"><a href="#redis-过期策略" class="headerlink" title="redis 过期策略"></a>redis 过期策略</h2><ul><li><p><strong>定期删除</strong>+ <strong>惰性删除</strong> + <strong>内存淘汰机制</strong></p><p><strong>定期删除</strong>: Redis默认是每隔100ms就随机抽取一些设置了过期时间的key. 假如redis中有100万个key, 都设置了过期时间,那么肯定不会每隔100毫秒就遍历100万个key然后删除过期了的key. <strong>当get某个key的时候, redis会检测该key有没有过期, 如果过期,就删除, 然后返回空.这就是惰性删除</strong>. 但是内存中如果有10万个key没有被访问到, 不可能让他们长期在内存中消耗内存, 这时候就需要走<strong>内存淘汰机制</strong></p><p>内存淘汰机制: </p><ul><li><p><strong>noeviction</strong>：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧</p></li><li><p><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，<strong>在键空间中</strong>，移除最近最少使用的key（这个是最常用的）</p></li><li><p><strong>allkeys-random</strong>：当内存不足以容纳新写入数据时，<strong>在键空间中</strong>，随机移除某个key，这个一般没人用吧</p></li><li><p><strong>volatile-lru</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，移除最近最少使用的key（这个一般不太合适）</p></li><li><p><strong>volatile-random</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，随机移除某个key</p></li><li><p><strong>volatile-ttl</strong>：当内存不足以容纳新写入数据时，<strong>在设置了过期时间的键空间中</strong>，有更早过期时间的key优先移除</p></li></ul></li></ul><h2 id="redis-cluster对mget的操作"><a href="#redis-cluster对mget的操作" class="headerlink" title="redis cluster对mget的操作"></a><strong>redis cluster对mget</strong>的操作</h2><p>Redis cluster不支持mget操作. 最初是facebook, 2010年使用memcache作缓存, 共有3000个节点. 发现节点太多, 连接频率下降. 继续增加节点, 并没有改善, 是因为IO的成本已经超过数据传输.</p><p>所以redis cluster也因此不支持mget操作.redis引入cluster模式后, 是将数据hash到<strong>16384</strong>个slot上, 每个node负责一部分slot.</p><p><strong>mget优化方案:</strong> </p><ol><li><p>n个key, 传统IO, 分别获取, 时间复杂度为O(n)</p></li><li><p>n个key, 通过Redis的hash算法可以得出各个key所对应的节点, 这样时间复杂度就位O(node.size())</p></li><li><p>在B方案的基础之上并发处理</p></li></ol><h2 id="redis的redlock"><a href="#redis的redlock" class="headerlink" title="redis的redlock"></a>redis的redlock</h2><ul><li><p><strong>redlock的前提是有N个redis的master, 这些节点之间没有主从复制, 或者其他集群协调机制.</strong></p></li><li><p>client从N个节点尝试获取锁, 只要有N/2 + 1个节点获取成功, 那么便获取成功; 如果最终获取失败, 客户端应该在所有的节点上进行解锁. </p></li><li><p>redlock的出发点是为了解决Redis集群环境下, 出现的分布式锁的问题(client1获取锁, master 宕机, slave变成master, client2获取到锁). 但是redlock的出现并没有解决这样的问题.</p></li></ul><p><strong><font color="#dd0000">Martin和Redis作者antirez之间的争辩:</font></strong></p><p>martin挑了两个缺点:</p><p>​    1. 对于提升效率的场景, redlock太重</p><p>​    2. 对于正确性要求极高的场景, redlock并不能保证正确性;</p><p><strong>问题:</strong> 在client1获取锁之后, 由于某种原因发生<strong>系统停顿</strong>, 锁过期, 然后client1执行操作; client2这时候也会拿到锁, 就会出现问题)</p><p><strong>问题:</strong> A, B, C, D, E 5个redis节点,如果C的时间走得快, client1拿到锁(A, B, C), C节点先过期, client2又拿到了(C, D, E)这样就出问题了;</p><p>所以Redis从根本上来说是AP, 而分布式锁是要求CP的.</p><h2 id="redis各种数据类型的数据结构"><a href="#redis各种数据类型的数据结构" class="headerlink" title="redis各种数据类型的数据结构"></a>redis各种数据类型的数据结构</h2><p>Redis的底层数据结构有以下几种：</p><ul><li>简单动态字符串sds(Simple Dynamic String)</li><li>双端链表(LinkedList)</li><li>字典(Map)</li><li>跳跃表(SkipList)</li></ul><p>redis各种数据类型使用的数据结构:</p><ul><li><p><strong>String</strong>, <strong>SDS</strong>(simple dynamic string) 简单动态字符串, 包含len(字符串长度), free(空闲的字节数量), buf(字节数组,存储数据)</p></li><li><p><strong>List</strong>, 使用<strong>压缩列表</strong>(数据集比较少的时候, 列表中单个数据小于64字节或者列表中数据个数少于512个)和<strong>双向循环链表</strong>, 包含pre, next, value</p></li><li><p><strong>hash</strong>, 使用<strong>压缩列表</strong>(键和值的大小小于64字节, 列表中键值对个数小于512个)和<strong>散列表</strong></p></li><li><p><strong>Set</strong>, <strong>有序数组</strong>(个数不超过512)和<strong>散列表</strong></p></li><li><p><strong>Zset</strong>, <strong>压缩列表</strong>(数据小于64字节或者个数小于128个)和<strong>跳跃表</strong></p></li></ul><h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;缓存穿透&quot;&gt;&lt;a href=&quot;#缓存穿透&quot; class=&quot;headerlink&quot; title=&quot;缓存穿透&quot;&gt;&lt;/a&gt;缓存穿透&lt;/h2&gt;&lt;p&gt;高并发下查询一个值，缓存中没有，数据库中也没有，布隆过滤器&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决方案：&lt;/strong&gt;&lt;/p
      
    
    </summary>
    
    
    
      <category term="Redis, 分布式, 缓存" scheme="http://yoursite.com/tags/Redis-%E5%88%86%E5%B8%83%E5%BC%8F-%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>kafka</title>
    <link href="http://yoursite.com/2020/01/19/kafka/"/>
    <id>http://yoursite.com/2020/01/19/kafka/</id>
    <published>2020-01-19T08:07:27.000Z</published>
    <updated>2020-01-20T03:19:08.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kafka应用场景"><a href="#kafka应用场景" class="headerlink" title="kafka应用场景"></a>kafka应用场景</h2><p>kafka是分布式消息系统，具有高吞吐量，可容错的发布-订阅消息系统。</p><p>应用场景:</p><ul><li><p>用户活动追踪</p></li><li><p>日志聚合</p></li><li><p>限流削峰</p></li></ul><p>高吞吐率实现：</p><ul><li>顺序读写</li><li>零拷贝</li><li>批量发送</li><li>消息压缩</li></ul><h2 id="kafka基本概念"><a href="#kafka基本概念" class="headerlink" title="kafka基本概念"></a>kafka基本概念</h2><ul><li><p><strong>Topic</strong>，相当于消息的一个主题，标签</p></li><li><p><strong>Partition</strong>，一个topic可以有多个partition，一个partition对应系统上的一个到多个目录。一个topic的partition数量应该是broker的整数倍。 </p></li><li><p><strong>segment</strong>，一个partition有多个segment组成，每个segment文件大小相等</p><p>文件由.log 和 .index文件组成，.index是存放.log文件中消息的索引</p><p>查看log文件：</p><p>bin/kafka-run-class.sh kafka.tools.DumpLogSegments –files /tmp/kafka-logs-3/test-0/00000000000000000000.log –print-data-log </p></li><li><p><strong>broker</strong>，kafka集群中的每个节点称为一个broker</p></li><li><p><strong>producer</strong>，消息的生产者</p></li><li><p><strong>consumer</strong>，消息的消费者，</p><ul><li><p>一个消费者可以消费多个topic的消息，</p></li><li><p>一个消费者可以消费一个topic的多个partition的消息</p></li><li><p>一个partition允许多个消费者同时消费</p></li></ul></li><li><p><strong>consumer group</strong>，消费者组，kafka保证一个消息只会被一个组中的某一个kafka消费。</p></li><li><p><strong>replicas of partition</strong>, 分区副本，为了防止消息丢失而创建的分区的备份。</p></li><li><p><strong>partition leader</strong>，每个partition有多个副本，而读写操作只能发生在leader上</p></li><li><p><strong>partition follower</strong>，所有follower都需要从leader同步消息,Leader与follower是主备关系，而非主从关系。</p></li><li><p><strong>ISR</strong>， In-Sync-Replicas,是指副本同步列表</p><ul><li><p><strong>AR</strong>，Assigned Replicas,在最初没有leader时，ISR=AR</p></li><li><p><strong>OSR</strong>，Outof-Sync-Replicas</p></li><li><p><strong>AR</strong> = ISR + OSR + Leader，ISR是存放在zk中的</p></li></ul></li><li><p><strong>offset</strong>,每条消息都有一个当前Partition下唯一的64字节的offset</p></li><li><p><strong>broker controller</strong>， kafka集群中有一个broker会被选举出来，作为controller，负责管理整个集群的partition和replicas的状态</p><p>只有broker controller会向zookeeper中注册watcher</p></li><li><p><strong>脑裂：（Brain Split）</strong>，由于某种原因导致高可用集群中出现了两个master。zk的watcher机制及分布式锁会引发master的假死，从而导致脑裂。</p></li><li><p><strong>HW（High Water-Mark）与 LEO（Log End Offset）</strong></p><ul><li><p>HW 是kafka消费者可以消费到的最高partition的偏移量，HW保证了kafka集群中消息的一致性。</p></li><li><p>LEO 是日志消息最后的偏移量</p></li><li><p>对于partition leader中新写入的消息，是不能立即被消费者消费的，只有当ISR中所有的partition follower消费之后，更新HW，写入ISR，此时消息才能被消费者消费。HW的更新速度取决于那个性能最差的broker</p></li></ul></li><li><p><strong>zookeeper</strong></p><ul><li><p>zookeeper负则broker controller的选举。</p></li><li><p>partition leader是由 broker controller负则选举的</p></li></ul></li></ul><ul><li><p><strong>Coordinator</strong></p><p>coordinator是用来管理消费者组的，是运行在每个broker上的group coordinator进程，主要负则offset的位移管理和rebalance,一个coordinator可以管理多个消费者组 </p></li><li><p><strong>rebalance</strong></p><p>当消费者组中的消费者数量发生变化，或者topic中的partition数量发生变化，会导致partition的重新分配，这个过程叫做Rebalance.</p><p>rebalance可以给系统带来高可用性和伸缩性，但是<strong>在Rebalance期间，消费者是无法读取消息的</strong>，因此要避免不必要的Rebalance</p></li></ul><p>  <strong>引发Rebalance的情形：</strong></p><ul><li>消费者组中添加消费者</li><li>消费者取消订阅，关闭或崩溃</li><li>向一个topic中添加新的partition</li><li>当有broker挂了</li></ul><ul><li><p><strong>offset commit</strong></p><p>消费者从partition中取出一批消息放入buffer中进行消费，在规定的时间内（seession.timeout.ms）消费完消息后，会自动将其消费的commit提交给broker，broker可以判断哪些消息有被消费过，若在规定时间内没有消费完毕，其是不会提交offset的, 可以避免在Rebalance时重复消费。</p></li></ul><p><strong>注:</strong> 从kafka0.9开始，offset保存在brokers中，__consumers-offsets</p><h2 id="kafka工作原理与流程"><a href="#kafka工作原理与流程" class="headerlink" title="kafka工作原理与流程"></a><strong>kafka工作原理与流程</strong></h2><ul><li><p><strong>消息路由</strong>（即写入的消息放入到哪个partition）</p><ul><li><p>若指定了partition,则写入指定的partition</p></li><li><p>若未指定partition，但指定了key，则对key取hash然后对partition个数取余</p></li><li><p>partition和key均为指定，则根据轮询算法选出一个partition</p></li></ul></li><li><p><strong>消息写入算法</strong>（即消息写入的过程）</p><ol><li><p>producer从zookeeper中获取partition的leader</p></li><li><p>producer将消息发送给leader</p></li><li><p>leader将消息写入到本地log</p></li><li><p>ISR中的follower从leader中pull消息，写入本地log后向leader发送ack</p></li><li><p>leader收到所有follower的ack后，增加HW并向producer发送ACK</p></li></ol></li><li><p><strong>HW截断机制</strong></p><p>HW截断机制保证了partition的leader宕机之后，leader与follower之间的数据不一致。</p><p>两种情况：</p><ul><li>当leader宕机之后，选举出一个新的leader，为了防止leader和follower的数据不一致，此时所有的FOLLOWER都要将数据截断到HW位置, 然后再同步新leader中的数据</li><li>当leader从宕机中恢复后，发现新的leader中和自己的数据不一致，此时宕机的leader会将数据截断到宕机之前的HW位置，然后同步新的leader中的数据</li></ul></li></ul><ul><li><p><strong>消息发送的可靠性机制</strong></p><p>producer向kafka发送消息时，可以选择需要的可靠性级别，通过request.required.acks参数的值进行设置</p><ul><li><p>0值（异步发送）</p><p>不需要kafka反馈成功ack，效率最高，可靠性最低，因为消息可能会丢失。消息丢失的情况：</p><ul><li><p>在传输途中丢失，网络原因</p></li><li><p>在broker中丢失，消息发到broker时是先放入到buffer，当broker的buffer满足将消息写入到partition时（容量到，时间到，或数量到）</p></li><li><p>在buffer正要写入到partition但还未写入时，新的消息又来了，可能丢失。</p></li><li><p>顺序与生产顺序不一致（网络原因）</p></li></ul></li><li><p>1值（同步发送）</p><p>消息发送成功后，立即向生产者返回ack(未等待ISR中的follower同步消息)</p><p>当leader收到新的消息后还未同步，leader宕机，新选举出的leader是不知道该信息存在的，造成消息的丢失。</p></li><li><p>-1值（同步发送）</p><p>leader收到消息，并向ISR列表中的所有FOLLOWER都同步了消息之后再向producer返回ack.</p><p>该模式消息几乎不会丢失，但有可能出现消息重复接收的情况。</p></li></ul></li></ul><ul><li><strong>消费者消费过程解析</strong><ul><li>消费者消费订阅的topic, broker controller会为消费者指定消息的partition，并将partition的offset发送给消费者</li><li>当有生产者向该partition中生产消息时，broker会将消息推送给消费者</li><li>消费者收到推送，消费该消息</li><li>消费者消费完该消息，向broker发送消费成功反馈</li><li>broker收到消费者反馈，更新partition中的offset</li></ul></li></ul><ul><li><p><strong>partition的leader选举范围</strong></p><p>partition的leader宕机后，broker controller从ISR中选举一个FOLLOWER成为新的leader，但若ISR中所有的FOLLOWER都宕机了, 则可以通过<strong>unclean.leader.election.enable</strong>的取值来设置leader的选举范围</p></li><li><p><strong>unclean.leader.election.enable</strong></p><ul><li><p>false</p><p>必须等到副本中有FOLLOWER活过来再进行新的选举，可靠性有保证，但可用性低。</p></li><li><p>true</p><p>选择任何一个没有宕机的FOLLOWER，但该FOLLOWER可能不在ISR中（OSR）。</p></li></ul></li></ul><ul><li><p><strong>重复消费及解决方案</strong></p><ul><li><p>同一个consumer重复消费</p><p>有一个消费的超时时间，auto.commit.interval.ms，在该时间内没有消费完消息，此时consumer会向broker提交一个异常，但是由于没有消费完，</p><p>所以没有向partition提交offset，所以再次消费时还是消费的同样的消息。</p></li><li><p>不同的consumer重复消费</p><p>当consumer消费了某条消息后，提交了offset，但是由于网络等原因，没有在session.timeout.ms中将该offset发送给broker，broker认为该consumer宕机，然后rebalnce,这个partition又被分配给了其他消费者，由于该partition的offset没有被修改，所以会再次被消费</p></li></ul></li></ul><p>​        <strong>解决方案</strong></p><p>​            增加auto.commit.interval.ms</p><p>​            设置enable.auto.commit为false，将kafka自动提交offset该为手动提交</p><p>​            手动提交分为：<strong>同步提交</strong>，<strong>异步提交</strong>，<strong>同异步联合提交</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SyncAsyncManualConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="string">"KafkaConsumerTest"</span>, <span class="keyword">false</span>);</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        String brokers = <span class="string">"kafkaOS1:9092,kafkaOS2:9092,kafkaOS3:9092"</span>;</span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers);</span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">"cityGro11"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="string">"false"</span>);</span><br><span class="line">        <span class="comment">// properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");</span></span><br><span class="line">        <span class="comment">// 设置一次提交的offset个数</span></span><br><span class="line">        properties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, <span class="number">10</span>);</span><br><span class="line">        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">"earliest"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">                <span class="string">"org.apache.kafka.common.serialization.IntegerDeserializer"</span>);</span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span><br><span class="line">               <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="keyword">this</span>.consumer = <span class="keyword">new</span> KafkaConsumer&lt;Integer, String&gt;(properties);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 指定要消费的主题</span></span><br><span class="line">  consumer.subscribe(Collections.singletonList(<span class="string">"cities"</span>));</span><br><span class="line">  ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(<span class="number">1000</span>);</span><br><span class="line">  <span class="keyword">for</span>(ConsumerRecord record : records) &#123;</span><br><span class="line">    System.out.print(<span class="string">"topic = "</span> + record.topic());</span><br><span class="line">    System.out.print(<span class="string">" partition = "</span> + record.partition());</span><br><span class="line">    System.out.print(<span class="string">" key = "</span> + record.key());</span><br><span class="line">    System.out.println(<span class="string">" value = "</span> + record.value());</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 带回调功能的手动异步提交</span></span><br><span class="line">      consumer.commitAsync((offsets, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">          System.out.print(<span class="string">"提交失败，offsets = "</span> + offsets);</span><br><span class="line">          System.out.println(<span class="string">"，exception = "</span> + e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;<span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      e.printStackTrace();</span><br><span class="line">      <span class="comment">// 同步提交</span></span><br><span class="line">      consumer.commitSync();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="kafka如何保证数据不丢失"><a href="#kafka如何保证数据不丢失" class="headerlink" title="kafka如何保证数据不丢失"></a><strong>kafka如何保证数据不丢失</strong></h2><ul><li><p>生产者数据的不丢失</p><ul><li><p>同步模式</p><p>​    request.required.acks = 1(follower 未同步数据)/-1(follower同步完数据,但效率低)</p></li><li><p>异步模式</p><p>通过设置时间阈值和消息数量阈值, 并且设置为阻塞模式</p><p>producer.type=async </p><p>request.required.acks=1 </p><p>queue.buffering.max.ms=5000 </p><p>queue.buffering.max.messages=10000 </p><p>queue.enqueue.timeout.ms = -1 </p><p>batch.num.messages=200</p></li></ul></li><li><p>消费者的数据不丢失</p><p>通过offset commit 来保证数据的不丢失，kafka自己记录了每次消费的offset数值，下次继续消费的时候，接着上次的offset进行消费即可</p></li></ul><h2 id="kafka性能到底好在哪儿"><a href="#kafka性能到底好在哪儿" class="headerlink" title="kafka性能到底好在哪儿"></a>kafka性能到底好在哪儿</h2><ul><li><p>采用<strong>BIO</strong>, 虽AIO性能更好, 但是编程难度较大</p></li><li><p>高性能的网络设计</p></li><li><p>顺序写</p><p> 客户端写数据—-&gt; 操作系统缓存 —-&gt; 写入磁盘(<strong>顺序写</strong>), 如果磁盘的个数和转数跟得上的话, 都快赶上写内存的速度了.</p></li><li><p>跳表, 稀松索引, 零拷贝</p></li></ul><h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;kafka应用场景&quot;&gt;&lt;a href=&quot;#kafka应用场景&quot; class=&quot;headerlink&quot; title=&quot;kafka应用场景&quot;&gt;&lt;/a&gt;kafka应用场景&lt;/h2&gt;&lt;p&gt;kafka是分布式消息系统，具有高吞吐量，可容错的发布-订阅消息系统。&lt;/p&gt;
&lt;p
      
    
    </summary>
    
    
    
      <category term="kafka, 分布式, MQ" scheme="http://yoursite.com/tags/kafka-%E5%88%86%E5%B8%83%E5%BC%8F-MQ/"/>
    
  </entry>
  
  <entry>
    <title>rabbitMQ</title>
    <link href="http://yoursite.com/2020/01/16/rabbitMQ/"/>
    <id>http://yoursite.com/2020/01/16/rabbitMQ/</id>
    <published>2020-01-16T08:53:13.000Z</published>
    <updated>2020-01-19T08:01:05.165Z</updated>
    
    <content type="html"><![CDATA[<h2 id="rabbitMQ简介"><a href="#rabbitMQ简介" class="headerlink" title="rabbitMQ简介"></a>rabbitMQ简介</h2><ul><li><p>按照官网的说法, rabbitMQ就像是一个邮局. 由Post Box, Post office, Post man组成</p></li><li><p>控制管理台: <span class="exturl" data-url="aHR0cDovL2xvY2FsaG9zdDoxNTY3Mi8=" title="http://localhost:15672/">http://localhost:15672/<i class="fa fa-external-link"></i></span></p></li><li><p>4种交换机: <strong>Fanout</strong> Exchange, <strong>Direct</strong> Exchange, <strong>Topic</strong> Exchange, <strong>Headers</strong> Exchange</p></li></ul><h2 id="图解rabbitMQ"><a href="#图解rabbitMQ" class="headerlink" title="图解rabbitMQ"></a>图解rabbitMQ</h2><p>Message has a routing key and queue has binded a routing key, if they are matched by the rules then the message will be sent to this queue.</p><p><img src="/2020/01/16/rabbitMQ/RabbitMQ.png" alt="图解rabbit MQ"></p><h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;rabbitMQ简介&quot;&gt;&lt;a href=&quot;#rabbitMQ简介&quot; class=&quot;headerlink&quot; title=&quot;rabbitMQ简介&quot;&gt;&lt;/a&gt;rabbitMQ简介&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;按照官网的说法, rabbitMQ就像是一个邮局. 由Po
      
    
    </summary>
    
    
    
      <category term="MQ, 分布式, 消息队列" scheme="http://yoursite.com/tags/MQ-%E5%88%86%E5%B8%83%E5%BC%8F-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>消息队列</title>
    <link href="http://yoursite.com/2020/01/15/MessageQueue/"/>
    <id>http://yoursite.com/2020/01/15/MessageQueue/</id>
    <published>2020-01-15T07:40:20.000Z</published>
    <updated>2020-01-19T08:03:13.809Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么使用消息队列"><a href="#为什么使用消息队列" class="headerlink" title="为什么使用消息队列"></a>为什么使用消息队列</h2><h3 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h3><p>​    譬如签到送积分, 签到和送积分是两个操作. 签到产生了很重要的数据, 它可以把该消息发送到MQ. 然后积分系统需要该数据, 从MQ中直接获取即可. 这样签到系统就做到了和积分系统解耦. 不必担心积分系统挂了怎么办, 是不是需要重试等. 这些都可以在积分系统内部自己实现. 再者, 如果以后另外一套系统也需要该签到数据, 直接从MQ中获取即可, 实际上与签到系统已无关系.</p><h3 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h3><p>​    当做到解耦后, 实际异步就是自然而然的事情. 如果签到只需要1ms, 而送积分, 或者其他操作需要500ms, 那不可能等所有操作完成之后再去返回数据给用户. 这样就做到了异步.</p><h3 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h3><p>​    削峰是指当并发访问高峰期, 通过MQ达到限流的目的, 从而减少对数据库MySQL的压力.</p><h2 id="消息队列有什么优点和缺点"><a href="#消息队列有什么优点和缺点" class="headerlink" title="消息队列有什么优点和缺点"></a>消息队列有什么优点和缺点</h2><p><strong>优点</strong>就是第一点所提到的<strong>解耦</strong>, <strong>异步</strong>, <strong>削峰</strong></p><p>缺点: </p><ul><li><p>系统可用性降低(当然有办法保证高可用), 相对而言</p></li><li><p>系统复杂度提高(这是引入新技术之后的必然结果), 因为随之而来的问题就是该技术本身的问题: 如何保证消息没有重复消费, 如何保证消息不丢失, 如何保证消息的顺序性等等</p></li><li><p>数据一致性问题(也可以归为系统复杂度提高的问题), 可以解决</p></li><li><p>如何保证消息的高可用</p></li><li><p>消息传递路径更长, 延时会增加</p></li><li><p>上游无法知道下游的执行结果(很致命)</p></li></ul><h2 id="MQ适合使用的场景"><a href="#MQ适合使用的场景" class="headerlink" title="MQ适合使用的场景"></a>MQ适合使用的场景</h2><ul><li><p>数据驱动的任务依赖. 如晚上执行的定时任务, task1, task2, task3, task2依赖task1, task3依赖task2</p></li><li><p>上游不关心执行结果. 如签到送积分, 修改/添加/删除数据要添加审计日志</p></li><li><p>上游关注执行结果,但执行时间很长. 如通过支付宝转账, 第三方把转账结果通过网关放入MQ, MQ再来通知用户 </p></li></ul><h2 id="MQ不适合使用场景"><a href="#MQ不适合使用场景" class="headerlink" title="MQ不适合使用场景"></a>MQ不适合使用场景</h2><p>上游需要依赖下游的执行结果, 如登录, 不能把登录成功的消息放入MQ</p><h2 id="各种MQ如何选择"><a href="#各种MQ如何选择" class="headerlink" title="各种MQ如何选择"></a>各种MQ如何选择</h2><ul><li><p>社区活跃度,: RabbitMQ和kafka &gt; rocketMQ(阿里) &gt; ActiveMQ</p></li><li><p>性能: kafka, rocketMQ &gt; RabbitMQ &gt; ActiveMQ</p></li><li><p>功能完善性: rocketMQ, rabbitMQ, activeMQ &gt; kafka</p></li></ul><p>所以中小公司, 没有自主研发能力的选择RabbitMQ, </p><p>如果大数据公司做实时计算, 日志采集建议用kafka</p><p>大公司可以使用rocketMQ, 因为用Java开发, 有问题自己可修改</p><h2 id="如何保证消息不被重复消费-消费的幂等性"><a href="#如何保证消息不被重复消费-消费的幂等性" class="headerlink" title="如何保证消息不被重复消费(消费的幂等性)"></a>如何保证消息不被重复消费(消费的幂等性)</h2><p><strong>重复消费的场景:</strong></p><ul><li>同一个消费者重复消费</li></ul><p>指定时间内未消费完, 没有提交offset, 下次消费时重复消费</p><ul><li>不同的消费者重复消费</li></ul><p>consumer消费完之后, 没有提交offset或者未提交成功offset, consumer挂了, 该消息被分配给了其他consumer, 导致重复消费</p><p><strong>问题解决:</strong></p><ul><li><p>设置超时时间</p></li><li><p>关闭自动提交, 改为手动提交, 提交之前检测数据库中是否有该消费过的数据</p></li></ul><h2 id="如何保证消息的可靠性传输-消息丢失问题"><a href="#如何保证消息的可靠性传输-消息丢失问题" class="headerlink" title="如何保证消息的可靠性传输(消息丢失问题)"></a>如何保证消息的可靠性传输(消息丢失问题)</h2><p><strong>消息丢失场景:</strong></p><ul><li><p>生产者丢失数据</p></li><li><p>MQ丢失数据</p></li><li><p>消费者丢失数据</p></li></ul><p><strong>问题解决:</strong></p><p>​    生产者要等MQ返回ack之后才认为该消息发送成功*<em>, *</em>否则重试.(异步发送ack或nack信号, 不用等待)</p><ul><li><p>RabbitMQ是通过持久化和confirm机制(即生产者要等MQ返回ack); </p></li><li><p>kafaka通过设置参数:</p><p>replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本</p><p>min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower</p><p>acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了</p><p>retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试</p></li><li><p>rabbitMQ和kafka关闭自动ack, 改为手动ack, 如果该消费者未提交ack, 那么MQ会分配其他消费者消费该消息;</p></li></ul><h2 id="如何保证消息的顺序性"><a href="#如何保证消息的顺序性" class="headerlink" title="如何保证消息的顺序性"></a>如何保证消息的顺序性</h2><p><strong>场景:</strong> 如现在需要做一个mysql binlog的同步系统, 如果原始顺序是create, update, delete, 如果是无序的就有可能变成delete, create, update, 这样就出错了.</p><p>RabbitMQ场景: 生产者放入顺序是data1, data2, data3, 因为有多个消费者, 所以有可能顺序会乱</p><p>kafka场景: 生产者放入data1, data2, data3,生产者指定key,可以让这3条数据放入一个partition,一个partition是由一个消费者来消费的, 但是消费者端肯定会起多个线程来消费消息, 多个线程并发, 顺序就可能乱掉了.</p><p><strong>解决:</strong></p><p>实际上所有的顺序一致性都是: 生产者  —&gt;  MQ server   —&gt; 消费者, 只要消息在生产者, MQ server和消费者中间是顺序一致的, 就能保证消息的顺序一致. 保证生产者消息放入MQ server中的时候, 相同key的数据只放入一个queue(或partition), 然后消费的时候由一个消费者来消费, 就能保证消息的顺序一致. 譬如下单, 扣款, 发货, 这三个消息, 只要保证同一个订单内部的一致性就可以. 不同订单没有因果关系, 所以可以不用保证不同订单之间的顺序一致.</p><h2 id="如何保证MQ的高可用"><a href="#如何保证MQ的高可用" class="headerlink" title="如何保证MQ的高可用"></a><strong>如何保证MQ的高可用</strong></h2><ul><li><p>rabbitMQ 通过镜像集群模式. 即创建的queue, 无论是元数据还是queue里的消息, 都会存在于多个实例上. 就是说每个rabbitMQ节点都有这个queue的一个完整镜像.包含queue的全部数据, 每次写消息到queue的时候, 都会自动把消息同步到多个queue上.</p></li><li><p>kafka天然的分布式消息队列, kafka集群由多个broker组成, 一个topic可以有多个partition, 每个partition存在于不同的broker上. 每个broker上只存partition的一部分数据. 每个partition都会有副本存在于其他broker上, 这样即使有broker宕机, 也可以重新选举出一个partition作为leader, 继续支持读写.</p></li></ul><h2 id="如何处理消息的延时以及过期失效问题"><a href="#如何处理消息的延时以及过期失效问题" class="headerlink" title="如何处理消息的延时以及过期失效问题"></a><strong>如何处理消息的延时以及过期失效问题</strong></h2><p>​    因为MQ,如rabbitMQ有ttl, 如果数据积压, 超过TTL时间不处理, 会直接丢掉.</p><p>​    这时候, 只能把这些数据进行批量重导, 重新灌入mq里面</p><h2 id="消息队列满了怎么处理"><a href="#消息队列满了怎么处理" class="headerlink" title="消息队列满了怎么处理"></a><strong>消息队列满了怎么处理</strong></h2><p>临时写个程序, 不做耗时操作, 操作一条废弃一条. 到系统并发量小的时候,譬如晚上12点的时候, 再做批量重导.</p><h2 id="有百万条消息积压几小时-怎么处理"><a href="#有百万条消息积压几小时-怎么处理" class="headerlink" title="有百万条消息积压几小时,怎么处理"></a>有百万条消息积压几小时,怎么处理</h2><p><strong>场景:</strong> MQ里积压了上千万条数据</p><p><strong>解决:</strong> </p><ol><li><p>查清楚是什么原因导致消息积压: consumer程序bug; consumer的消费速度落后于producer的生产速度;</p></li><li><p>如果仅是consumer的的消费速度落后于生产速度的话, 考虑扩容即可</p></li><li><p>若是consumer故障, 修复consumer, 并将其停掉</p></li><li><p>重新创建一个容量大的topic, 比如partition是原来的10倍</p></li><li><p>编写一个新的consumer, 消费原来积压的队列, 该consumer不做任何耗时的操作,将消息均匀的写入新创建的队列里</p></li><li><p>将修复好的consumer部署到原来10倍机器上消费队列</p></li><li><p>消息积压解决后, 恢复原有架构</p></li></ol><h2 id="如何自己设计一个消息队列"><a href="#如何自己设计一个消息队列" class="headerlink" title="如何自己设计一个消息队列"></a>如何自己设计一个消息队列</h2><p>首先要理解kafka的原理</p><ul><li><p>broker –&gt; topic –&gt; partition, 如果资源不够用了, 就给topic增加partition, 提高吞吐量</p></li><li><p>mq要顺序落盘</p></li><li><p>高可用partition 副本, leader, broker</p></li><li><p>解决数据0丢失</p></li></ul><h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么使用消息队列&quot;&gt;&lt;a href=&quot;#为什么使用消息队列&quot; class=&quot;headerlink&quot; title=&quot;为什么使用消息队列&quot;&gt;&lt;/a&gt;为什么使用消息队列&lt;/h2&gt;&lt;h3 id=&quot;解耦&quot;&gt;&lt;a href=&quot;#解耦&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
    
      <category term="MQ, 消息队列, 分布式" scheme="http://yoursite.com/tags/MQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务</title>
    <link href="http://yoursite.com/2020/01/14/DistributeTransaction/"/>
    <id>http://yoursite.com/2020/01/14/DistributeTransaction/</id>
    <published>2020-01-14T06:00:03.000Z</published>
    <updated>2020-01-19T08:02:32.369Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是分布式事务？"><a href="#什么是分布式事务？" class="headerlink" title="什么是分布式事务？"></a>什么是分布式事务？</h2><p>简单的说，就是一次大操作由不同小操作组成，这些小操作分布在不同服务器上，分布式事务需要保证这些小操作要么全部成功，要么全部失败.</p><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a><strong>两阶段提交</strong></h2><p>两阶段提交简称2PC(two phase commitment)</p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul><li>TM(Transaction Manager) 事务管理器</li><li>RM(Resource Manager) 资源管理器</li></ul><h3 id="两阶段提交-1"><a href="#两阶段提交-1" class="headerlink" title="两阶段提交:"></a>两阶段提交:</h3><ul><li><p>在第一阶段, 资源管理器向事务管理器汇报各自事务的状态;</p></li><li><p>在第二阶段, 事务管理器根据资源管理器汇报的状态来来确定是回滚还是提交;</p></li></ul><p><strong><font color="#dd0000">注: 两阶段提交方案锁定资源时间长，对性能影响很大，基本不适合解决微服务事务问题.</font></strong></p><p>​      <strong><font color="#dd0000">两阶段提交协议是基于XA规范, 阻塞, 属于刚性事务</font></strong></p><p>​    数据库实现(XA, MySQL和Oracle都支持)</p><p>​    xa_start, xa_end, xa_prepare, xa_commit, xa_rollback</p><h2 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a><strong>TCC</strong></h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>​    TCC(Try Confirm Cancel), 是2PC的一种改进</p><p>​    事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后事务协调器会根据try接口返回情况，决定调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>TCC方案让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。 当然TCC方案也有不足之处，集中表现在以下两个方面：</p><ul><li><p>对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。</p></li><li><p>实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。</p></li></ul><h2 id="基于消息的最终一致性方案"><a href="#基于消息的最终一致性方案" class="headerlink" title="基于消息的最终一致性方案"></a><strong>基于消息的最终一致性方案</strong></h2><p>消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。</p><p>消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。</p><h2 id="阿里的GTS"><a href="#阿里的GTS" class="headerlink" title="阿里的GTS"></a><strong>阿里的GTS</strong></h2><p>Fescar（Fast &amp; EaSy Commit And Rollback), 升级后为: Seata(Simple Extensible Autonomous Transaction Architecture) </p><h3 id="seata-工作原理"><a href="#seata-工作原理" class="headerlink" title="seata 工作原理"></a>seata 工作原理</h3><p>下面是来自于<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NlYXRhL3NlYXRh" title="https://github.com/seata/seata">seata<i class="fa fa-external-link"></i></span>的工作原理图</p><p><img src="/2020/01/14/DistributeTransaction/seata-procedure.png" alt="seata flow chart"></p><ul><li><strong>Transaction Coordinator(TC):</strong> 用来协调全局事务和各个分支事务的状态, 驱动全局事务和各个分支事务的回滚或提交</li><li><strong>Transaction Manager(TM):</strong> 定义了事务的范围(一般是业务层), 用来<strong>开启/提交/回滚</strong>一个整体事务</li><li><strong>Resource Manager(RM):</strong> 管理分支事务, 与TC进行协调注册分支事务并且汇报分支事务的状态, 驱动分支事务的提交或回滚</li></ul><h3 id="seata管理分布式事务的生命周期"><a href="#seata管理分布式事务的生命周期" class="headerlink" title="seata管理分布式事务的生命周期"></a>seata管理分布式事务的生命周期</h3><pre><code>1. TM向TC请求开启一个新的全局事务, TC生成一个代表该全局事务的XID 2. XID在整个microservice的整个调用链中都可见 3. RM把本地事务向TC注册为XID全局事务的一个分支 4. TM向TC请求XID全局事务的提交或回滚 5. TC驱动所有XID全局事务的提交或回滚</code></pre><h2 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a><strong>数据一致性</strong></h2><h3 id="数据不一致产生的原因"><a href="#数据不一致产生的原因" class="headerlink" title="数据不一致产生的原因"></a>数据不一致产生的原因</h3><ul><li><p>不同的DB(用户有UserDB, 商品有Product DB)</p></li><li><p>DB和缓存(商品有Product DB 和 Product Cache)</p></li></ul><p>问题1: 如果把下单操作和把下单消息放到MQ的操作放到一个try-catch块中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// 下单</span></span><br><span class="line">  orderService.createOrder();</span><br><span class="line">  <span class="comment">// 发送消息到MQ</span></span><br><span class="line">  msgClient.sendMsg(orderId);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发送消息是网络操作, 网络操作一般会有3中结果: success, fail, timeout. Success 和 fail都相对好处理, 但是<strong>timeout</strong>是不知道消息发送成功还是失败的.所以这种操作是<strong>不合理</strong>的. </p><p><strong>解决方法: 一般会先把下单成功的消息放入DB中, 然后从DB中取数据放入MQ</strong></p><p><strong>分布式缓存和数据库的一致性4步骤:</strong></p><ul><li><p>先更新数据库, 然后delete缓存</p></li><li><p>延时双删</p></li><li><p>设置缓存失效时间</p></li><li><p>记录日志, 脚本定期修正</p></li></ul><h2 id="柔性分布式事务-saga"><a href="#柔性分布式事务-saga" class="headerlink" title="柔性分布式事务(saga)"></a>柔性分布式事务(saga)</h2><p>Saga模式是现实中可行的方案，采用事务补偿机制。每个本地事务都存储一个副本，如果出现失败，则利用补偿机制回滚。</p><p>TCC模型和saga模型</p><p>TCC(Try, Confirm, Cancel), 以A向B账户转账为例, 分为汇款服务和收款服务</p><h3 id="saga-汇款服务"><a href="#saga-汇款服务" class="headerlink" title="saga-汇款服务:"></a><strong>saga-汇款服务:</strong></h3><ul><li><p>Try:</p><ol><li><p>检查A账户的有效性, 账户状态,是否冻结等, </p></li><li><p>账户余额是否充足</p></li><li><p>从A账户中扣减500元, 并将状态置为转账中</p></li><li><p>预留扣减资源, 将A往B账户转账这个事件存入MQ(或DB)中</p></li></ol></li><li><p>Confirm:</p><p>不做任何操作</p></li><li><p>Cancel:</p><ol><li><p>A账户增加500元</p></li><li><p>从MQ(或DB)中,释放扣减资源</p></li></ol></li></ul><h3 id="saga-收款服务"><a href="#saga-收款服务" class="headerlink" title="saga-收款服务:"></a><strong>saga-收款服务:</strong></h3><ul><li><p>Try:</p><p>检查B账户的有效性</p></li><li><p>Confirm:</p><ol><li><p>读MQ(或DB), B账户增加500元</p></li><li><p>从MQ(或DB)释放扣减资源</p></li></ol></li><li><p>Cancel:</p><p>不做任何操作</p></li></ul><p><strong>saga模型:</strong></p><p>把一个长事务拆分成多个短事务(本地事务), 每个事务都有对应的执行模块和补偿模块(对应TCC中的Confirm 和 Cancel)</p><ul><li><p>当任意一个本地事务出错, 就根据本地事务的补偿方法恢复之前的事务, 达到事务的最终一致性.</p></li><li><p>当最后一个本地事务失败时, 整个事务就失败, 不需要补偿. 所以针对N个本地事务, 只有对应N - 1个事务补偿</p></li></ul><p><strong>saga vs TCC</strong></p><p>​    区别在于TCC多了一个Try(<strong>预操作</strong>), 每次都会预扣减资源. saga虽然也有Try操作, 但是只是做一些检测操作</p><p><strong>saga 时序图</strong></p><p><img src="/2020/01/14/DistributeTransaction/saga-sequence-chart.png" alt="saga sequence chart"></p><p> <strong>TCC时序图</strong></p><p><img src="/2020/01/14/DistributeTransaction/TCC-sequence-chart.png" alt="tcc sequence chart"></p><p><strong><font color="#dd0000">刚性事务vs 柔性事务</font></strong></p><table><thead><tr><th></th><th><strong>刚性事务(XA模型)</strong></th><th><strong>柔性事务</strong></th></tr></thead><tbody><tr><td><strong>实际项目中有无应用场景</strong></td><td><strong>无</strong></td><td><strong>有</strong></td></tr><tr><td><strong>回滚</strong></td><td><strong>支持</strong></td><td><strong>通过补偿支持</strong></td></tr><tr><td><strong>一致性</strong></td><td><strong>强一致性</strong></td><td><strong>最终一致性</strong></td></tr><tr><td><strong>隔离性</strong></td><td><strong>原生支持</strong></td><td><strong>实现资源锁定接口(如信用卡预授权)</strong></td></tr><tr><td><strong>并发性能</strong></td><td><strong>低, 严重衰退(锁定资源时间太久)</strong></td><td><strong>略微衰退</strong></td></tr><tr><td><strong>适合场景</strong></td><td><strong>短事务,并发较低</strong></td><td><strong>长事务, 高并发</strong></td></tr></tbody></table><h2 id="redis做分布式锁的问题"><a href="#redis做分布式锁的问题" class="headerlink" title="redis做分布式锁的问题"></a><strong>redis做分布式锁的问题</strong></h2><p><strong>SET lock_key random_value NX PX 5000</strong></p><ul><li><p><strong>锁没有办法严格保证唯一</strong>, 如使用master-slave模式, 当线程A通过setnx(orderId,…)拿到锁, 执行操作, 此时master挂掉, slave变为master, 原有的锁记录丢失. 线程B这时可以拿到锁, 就出现问题</p></li><li><p><strong>Redis锁存在租约问题</strong>,  如果操作执行时间超过了锁的有效期, 那么线程B同样会拿到锁 </p></li></ul><p><strong>注: redis从本质上说是AP模型, 只保证可用. 如果需要用分布式锁, 必须是CP模型, 需要保证一致性.etcd可以保证.</strong></p><p><img src="/2020/01/14/DistributeTransaction/distribute-transaction-consistent.png" alt="consistent"> </p><h2 id="分布式缓存的高可用"><a href="#分布式缓存的高可用" class="headerlink" title="分布式缓存的高可用"></a><strong>分布式缓存的高可用</strong></h2><p>缓存不可用, 查询数据库,</p><p>做好评估:  缓存宕机, 评估数据库压力持续更新(注)</p><h2 id="持续更新-注"><a href="#持续更新-注" class="headerlink" title="持续更新(注)"></a>持续更新(注)</h2><p>该篇blog并不代表该知识点的所有内容, 在今后的工作学习中, <strong><font color="#dd0000">持续更新</font></strong>! 如对blog中的观点有异议/建议,请发送email至: <span class="exturl" data-url="bWFpbHRvOnNoY2hhb3NodWFpQGZveG1haWwuY29t" title="mailto:shchaoshuai@foxmail.com">shchaoshuai@foxmail.com<i class="fa fa-external-link"></i></span>, 感谢您的阅读.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;什么是分布式事务？&quot;&gt;&lt;a href=&quot;#什么是分布式事务？&quot; class=&quot;headerlink&quot; title=&quot;什么是分布式事务？&quot;&gt;&lt;/a&gt;什么是分布式事务？&lt;/h2&gt;&lt;p&gt;简单的说，就是一次大操作由不同小操作组成，这些小操作分布在不同服务器上，分布式事务需
      
    
    </summary>
    
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
</feed>
